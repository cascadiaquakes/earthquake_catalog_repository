{"version":3,"kind":"Notebook","sha256":"d33d49d761b1052a6e38b0a4d813957a3401befc403c63c91596202e2c35576e","slug":"gnn-3d-sin-testing","location":"/notebooks/Loic/GNN/other versions/GNN_3D_sin_testing.ipynb","dependencies":[],"frontmatter":{"title":"Training a GNN: Node level pred","content_includes_title":false,"kernelspec":{"name":"conda-env-pangeo_torch-py","display_name":"Python [conda env:pangeo_torch]","language":"python"},"authors":[{"id":"Amanda M. Thomas, William Marfo, and Loïc Bachelot","name":"Amanda M. Thomas, William Marfo, and Loïc Bachelot"}],"keywords":["earthquake","catalog","ML","AI"],"numbering":{"title":{"offset":4}},"exports":[{"format":"ipynb","filename":"GNN_3D_sin_testing.ipynb","url":"/GNN_3D_sin_testing-cab8e334b76889778aa5de26fece0cbe.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Parameters of simualation:","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"j2SPPCzaNj"}],"key":"bflRnDVBEc"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Domain size = 6*6","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"bjUSVITvzj"}],"key":"gQ7NLHDqPg"}],"key":"v1vy4CRRWo"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"signal size = 10","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"pbl89Zfm41"}],"key":"xLMDHxFgZh"}],"key":"dlBhfXDIIN"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"number station = 5-15","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IXzuJQzX9K"}],"key":"oOvx2eY2hN"}],"key":"DmpgHa6yF4"}],"key":"hkljmDd2eW"}],"key":"HV7L3uzTSK"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import pickle\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch_geometric.data import Data\nimport torch\nimport torch_geometric\nfrom torch_geometric.transforms import KNNGraph\nfrom torch_geometric.data import InMemoryDataset, Data\nfrom torch.nn import Linear, Parameter, LeakyReLU, Conv2d, MaxPool1d\nfrom torch_geometric.nn import GCNConv, MessagePassing, MLP\nfrom scipy.spatial import distance\nfrom torch_geometric.utils import add_self_loops, degree\nfrom tqdm import tqdm","visibility":"show","key":"A5vuya0cPO"},{"type":"outputs","id":"Qs2KlCM4T70e1PlNKyQW2","children":[],"visibility":"show","key":"R9zt2DfEm7"}],"visibility":"show","key":"fmGSdkQlIL"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def visualize_graph_torch(g, color):\n    fig, ax = plt.subplots(figsize=(6,6))\n    # add edges\n    for edge in g.edge_index.T:\n        ax.plot([g.pos[edge[0]][0], g.pos[edge[1]][0]], [g.pos[edge[0]][1], g.pos[edge[1]][1]], color='Blue', linewidth=1)\n    scatter = ax.scatter(x=g.pos.T[0], y=g.pos.T[1], alpha=1, c=g[color][:,0], s=150)\n    legend1 = ax.legend(*scatter.legend_elements(), loc='center left', bbox_to_anchor=(1, 0.5))\n    ax.add_artist(legend1)\n    plt.show()","visibility":"show","key":"PSJ6kz5Hla"},{"type":"outputs","id":"1gBN0kCSYHogg7ObkS_31","children":[],"visibility":"show","key":"asc9aqGrvL"}],"visibility":"show","key":"Vv61hNlG34"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"SIGNAL_SIZE = 10\n#NB_NODES = 50\nNB_GRAPHS = 10","visibility":"show","key":"lARgBHJCIZ"},{"type":"outputs","id":"Xyf3LXCz1sbTURdh0EBTD","children":[],"visibility":"show","key":"KCvrNdHnUg"}],"visibility":"show","key":"hCOyTAfbfW"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def add_edge_weight(g):\n    edge_weight = []\n    for edge in g.edge_index.T:\n        edge_weight.append(1/(distance.euclidean((g.pos[edge[0]][0], g.pos[edge[0]][1]), (g.pos[edge[1]][0], g.pos[edge[1]][1]))+1))\n    g.edge_weight = torch.tensor(np.array(edge_weight)).type(torch.FloatTensor)\n    return g","visibility":"show","key":"Y13W8Oxohx"},{"type":"outputs","id":"QOZkzPR8JVXRUK1TxQiE-","children":[],"visibility":"show","key":"Kw2fqHk9XT"}],"visibility":"show","key":"fWobv78B98"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"class SinDataset(InMemoryDataset):\n\n    def __init__(self, root, transform=None, pre_transform=None, nb_graph=10):\n        self.nb_graph = nb_graph\n        super(SinDataset, self).__init__(root, transform, pre_transform)\n        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n\n    @property\n    def raw_file_names(self):\n        # List of the raw files\n        return 0\n\n    @property\n    def processed_file_names(self):\n        return 'data.pt'\n\n    def process(self):\n        # Read the file netcdf and create dataset\n        data_list = []\n\n        for graph in range(self.nb_graph):\n            \n            nb_nodes = np.random.randint(5, 15)\n            pos = torch.tensor(np.array(np.random.uniform(low=0, high=6, size=nb_nodes*2)).reshape(-1, 2)).type(torch.FloatTensor)        \n        \n            # create signal\n            sin = []\n            origin = np.random.randint(0, 6, size=2)\n            for i in range(nb_nodes):\n                dist = distance.euclidean(origin, (pos[i][0], pos[i][1]))\n                sin.append(np.sin(np.arange(dist, dist+SIGNAL_SIZE)[:SIGNAL_SIZE]))\n            signal = torch.tensor(np.array(sin)).type(torch.FloatTensor).reshape(-1, SIGNAL_SIZE)\n        \n            # create the n different graphs based on mask\n            for i in range(nb_nodes):\n                g = Data(pos=pos, signal=signal)\n                mask = torch.tensor(np.zeros(nb_nodes)).type(torch.BoolTensor)\n                mask[i] = True\n                g.train_mask = mask\n                data_list.append(g)\n            \n        if self.pre_transform is not None:\n            data_list = [self.pre_transform(data) for data in data_list]\n            data_list = [add_edge_weight(data) for data in data_list]\n        \n\n        # Store the processed data\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])","visibility":"show","key":"GvNuAfRm3m"},{"type":"outputs","id":"BwqhG2HtR3QEFFDp59aYj","children":[],"visibility":"show","key":"oUXP3WKGo7"}],"visibility":"show","key":"yorNE9aDm1"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"dataset = SinDataset(root=\"./sin_train_masked\", pre_transform=KNNGraph(k=5, loop=False, force_undirected=True), \n                       nb_graph=NB_GRAPHS)\ndataset","visibility":"show","key":"LE2QxAoOfG"},{"type":"outputs","id":"HQvk1dMTDFC68muCwFv8t","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":8,"metadata":{},"data":{"text/plain":{"content":"SinDataset(85)","content_type":"text/plain"}}},"children":[],"key":"o8onZTPv3s"}],"visibility":"show","key":"IMlhLyoWf6"}],"visibility":"show","key":"MsEgkjdLhg"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"data = dataset[0]\ndata","visibility":"show","key":"WjfdNG2xgg"},{"type":"outputs","id":"llIbe_6p9NaU5-GXiVAkh","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"Data(pos=[14, 2], signal=[14, 10], train_mask=[14], edge_index=[2, 86], edge_weight=[86])","content_type":"text/plain"}}},"children":[],"key":"kKXmnMGV4o"}],"visibility":"show","key":"wooM7s21Gd"}],"visibility":"show","key":"zCxWHAtX0l"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"visualize_graph_torch(data, color='signal')","visibility":"show","key":"hgD0jfKSFP"},{"type":"outputs","id":"r6w9wWdGA6IEAjgYKlIiR","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"2bd2d1b4457f412b87d36fe7d3c6a7d4","path":"/2bd2d1b4457f412b87d36fe7d3c6a7d4.png"},"text/plain":{"content":"<Figure size 600x600 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"XpDJnYw2Ph"}],"visibility":"show","key":"mpHOfAYEvP"}],"visibility":"show","key":"MqyS33Kazu"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"for i in range(data.signal.shape[0]):\n    plt.plot(data.signal[i], label=i)\n#plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))","visibility":"show","key":"j20Vbx4H9q"},{"type":"outputs","id":"9uM7-_OtrqNdxAxuYL0l6","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"9f4b2587b25ab6bb307f250f3a0a3d41","path":"/9f4b2587b25ab6bb307f250f3a0a3d41.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"zx0X5vabX0"}],"visibility":"show","key":"tZfwPoubLO"}],"visibility":"show","key":"JsY6t3ilOl"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"class BasicNet(torch.nn.Module):\n    \"\"\"\n    BasicNet is a Graph Convolutional Network (GCN) model with a Multi-layer Perceptron (MLP) structure.\n    Arguments:\n        channels_x (int): The number of features in the node feature matrix `x`.\n        channels_y (int): The number of features in the node feature matrix `y`.\n        hidden_channels (int, optional): The number of hidden channels in GCNConv layer. Default: 10.\n        dropout (float, optional): The dropout rate to be applied to the MLP layers. Default: 0.3.\n\n    Attributes:\n        conv (GCNConv): A graph convolutional layer.\n        mlp_in (MLP): The input MLP that transforms the concatenation of `x` and `signal` into hidden representation.\n        mlp_out (MLP): The output MLP that transforms the hidden representation from `mlp_in` into final node feature matrix `y`.\n    \"\"\"\n    def __init__(self, channels_x, channels_y, hidden_channels=10, dropout=0.3):\n        super(BasicNet, self).__init__()\n        torch.manual_seed(1234)\n        channels_extr = channels_y\n        self.pooling = MaxPool1d(2)\n        self.feature_extraction1 = Conv2d(1, 2, (1, 3), padding=(0, 1))\n        self.feature_extraction2 = Conv2d(2, 2, (1, 3), padding=(0, 1))\n        self.feature_extraction3 = Conv2d(2, 2, (1, 3), padding=(0, 1))\n        channels_extr = channels_extr*8//pow(2, 3) #channels input*nb channels last conv /2^nb pooling for kernel 2\n        \n        self.mlp_in = MLP([channels_extr+channels_x, hidden_channels])\n        # self.mlp_in = MLP([channels_y+channels_x, hidden_channels])\n        self.conv = GCNConv(hidden_channels, hidden_channels)\n        self.mlp_out = MLP([hidden_channels, 256, 256, channels_y])\n\n    \n    def forward(self, x, signal, edge_index, edge_weight, mask):\n        \"\"\"\n        Perform a forward pass through the network.\n\n        Arguments:\n            x (torch.Tensor): Node feature matrix with shape `(num_nodes, channels_x)`.\n            signal (torch.Tensor): Node feature matrix with shape `(num_nodes, channels_y)`.\n            edge_index (torch.Tensor): Edge indices with shape `(2, num_edges)`.\n            edge_weight (torch.Tensor): Edge weight with shape `(num_edges,)`.\n            mask (torch.Tensor): Mask indicating which nodes to use for training with shape `(num_nodes,)`.\n\n        Returns:\n            torch.Tensor: The final node feature matrix `y` with shape `(num_nodes, channels_y)`.\n        \"\"\"\n        signal = (signal.T*(~mask)).T\n        signal = self.feature_extraction1(signal.reshape(1, signal.shape[0], signal.shape[1]))\n        signal = self.pooling(signal)\n        # signal = self.feature_extraction2(signal)\n        # signal = self.pooling(signal)\n        # signal = self.feature_extraction3(signal)\n        # signal = self.pooling(signal)\n        signal = torch.flatten(torch.permute(signal, (1, 0 ,2)), start_dim=1)\n        # out = signal\n        out = torch.cat([x, signal], dim=-1)\n        out = self.mlp_in(out)\n        out = self.conv(out, edge_index, edge_weight)\n        # out = self.conv2(out, edge_index, edge_weight)\n        out = self.mlp_out(out)\n        return out.tanh()\n    \nmodel = BasicNet(data.pos.shape[1], data.signal.shape[1], hidden_channels=128)\nprint(model)","visibility":"show","key":"rzqJaPhgAP"},{"type":"outputs","id":"Ss2SKfY0Zw_0YEwnGHbm8","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"BasicNet(\n  (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (feature_extraction1): Conv2d(1, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n  (feature_extraction2): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n  (feature_extraction3): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n  (mlp_in): MLP(12, 128)\n  (conv): GCNConv(128, 128)\n  (mlp_out): MLP(128, 256, 256, 10)\n)\n"},"children":[],"key":"ea1mbD0kmx"}],"visibility":"show","key":"jit36AszMq"}],"visibility":"show","key":"UHJ5sEgVhW"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"from torch_geometric.loader import DataLoader\nfrom sklearn.model_selection import train_test_split\n\ntrain_dataset, val_dataset = train_test_split(dataset, train_size=0.5, random_state=42)\nval_dataset, test_dataset = train_test_split(val_dataset, train_size=0.8, random_state=42)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n\nprint(f\"nb graph train ds= {len(train_dataset)}, nb graph val ds= {len(val_dataset)}\")","visibility":"show","key":"noglMLTEg6"},{"type":"outputs","id":"yPC8XKbxf7S7bJWuD3ffk","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"nb graph train ds= 42, nb graph val ds= 34\n"},"children":[],"key":"ihftNGlTQb"}],"visibility":"show","key":"SkXkXPZKIy"}],"visibility":"show","key":"QJ7ygDy83y"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"data = train_dataset[0]\ndata","visibility":"show","key":"Bt8DPfOap3"},{"type":"outputs","id":"CG2M5jIvk6qaMpADE0M_P","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":15,"metadata":{},"data":{"text/plain":{"content":"Data(pos=[14, 2], signal=[14, 10], train_mask=[14], edge_index=[2, 86], edge_weight=[86])","content_type":"text/plain"}}},"children":[],"key":"imBxFn3Bpu"}],"visibility":"show","key":"VLsHncAAKL"}],"visibility":"show","key":"vfM9WJ08n2"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport torch\n\nclass EarlyStopper:\n    \"\"\"\n    A class for early stopping the training process when the validation loss stops improving.\n    \n    Parameters:\n    -----------\n    patience : int, optional (default=1)\n        The number of epochs with no improvement in validation loss after which training will be stopped.\n    min_delta : float, optional (default=0)\n        The minimum change in the validation loss required to qualify as an improvement.\n    \"\"\"\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.min_validation_loss = np.inf\n\n    def early_stop(self, validation_loss):\n        \"\"\"\n        Check if the training process should be stopped.\n        \n        Parameters:\n        -----------\n        validation_loss : float\n            The current validation loss.\n            \n        Returns:\n        --------\n        stop : bool\n            Whether the training process should be stopped or not.\n        \"\"\"\n        if validation_loss < self.min_validation_loss:\n            self.min_validation_loss = validation_loss\n            self.counter = 0\n        elif validation_loss > (self.min_validation_loss + self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n    \n\ndef train(dataloader, device):\n    \"\"\"\n    Train the model on a given dataloader.\n    \n    Parameters:\n    -----------\n    dataloader : DataLoader\n        A PyTorch DataLoader containing the training data.\n        \n    Returns:\n    --------\n    mean_loss : float\n        The mean loss over all batches in the dataloader.\n    \"\"\"\n    model.train()\n    mean_loss = 0\n    for batch in dataloader:\n        batch = batch.to(device)\n        optimizer.zero_grad()  # Clear gradients.\n        out = model(batch.pos, batch.signal, batch.edge_index, batch.edge_weight, batch.train_mask)  # Perform a single forward pass.\n        loss = criterion(out[batch.train_mask], batch.signal[batch.train_mask])  # Compute the loss solely based on the training nodes.\n        loss.backward()  # Derive gradients.\n        optimizer.step()  # Update parameters based on gradients.\n        mean_loss += loss\n    return float(mean_loss/len(dataloader))\n\n\n@torch.no_grad()\ndef validation(dataloader, device):\n    \"\"\"\n    Compute the validation loss on a given dataloader.\n    \n    Parameters:\n    -----------\n    dataloader : DataLoader\n        A PyTorch DataLoader containing the validation data.\n        \n    Returns:\n    --------\n    mean_loss : float\n        The mean loss over all batches in the dataloader.\n    \"\"\"\n    model.eval()\n    loss = 0\n    for data in dataloader:\n        data = data.to(device)\n        out = model(data.pos, data.signal, data.edge_index, data.edge_weight, data.train_mask)\n        loss += criterion(out[data.train_mask], data.signal[data.train_mask])\n    return float(loss/len(dataloader))","visibility":"show","key":"ZXARoNceid"},{"type":"outputs","id":"X8ykUiyrpx5H9NA9jmQ_c","children":[],"visibility":"show","key":"Bub5vIVTJ5"}],"visibility":"show","key":"TsdvHn2h0P"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# device = torch.device('cpu')\n\n\nmodel = BasicNet(data.pos.shape[1], data.signal.shape[1], hidden_channels=128).to(device)\n\ncriterion = torch.nn.MSELoss()  # Define loss criterion.\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Define optimizer.\nearly_stopper = EarlyStopper(patience=20, min_delta=0.0)\nprint(device)","visibility":"show","key":"y7f2oAsTmS"},{"type":"outputs","id":"e4-sev_z_rNYYO-BVWcVc","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"cpu\n"},"children":[],"key":"sv7Rsrjnbp"}],"visibility":"show","key":"PtGXFRYqXo"}],"visibility":"show","key":"rLuoNHf3sk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"model","key":"W7PJeZJArB"},{"type":"outputs","id":"HcQVcWBulxf5KnD8zSKdr","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":18,"metadata":{},"data":{"text/plain":{"content":"BasicNet(\n  (pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (feature_extraction1): Conv2d(1, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n  (feature_extraction2): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n  (feature_extraction3): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n  (mlp_in): MLP(12, 128)\n  (conv): GCNConv(128, 128)\n  (mlp_out): MLP(128, 256, 256, 10)\n)","content_type":"text/plain"}}},"children":[],"key":"rcseP3wKkp"}],"key":"rRo2xGTv6V"}],"key":"ICSXS5mLgx"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import time\nloss_train = []\nloss_val = []\nbest_loss = 1\nbest_epoch = 0\nPATH_CHECKPOINT = \"./checkpoint/best_masked.pt\"\nstart_time = time.perf_counter()\n\nnb_epoch = tqdm(range(5000))\n\nfor epoch in nb_epoch:\n    loss_train.append(train(train_loader, device))\n    loss_val.append(validation(val_loader, device))\n    \n    if loss_val[-1] < best_loss:\n        best_loss = loss_val[-1]\n        best_epoch = epoch\n        torch.save(model.state_dict(), PATH_CHECKPOINT)\n    if early_stopper.early_stop(loss_val[-1]):\n        print(f\"early stopping at epoch {epoch}: train loss={loss_train[-1]}, val loss={loss_val[-1]}\")\n        break\n    nb_epoch.set_postfix_str(f\"train loss={loss_train[-1]}, val loss={loss_val[-1]}\")\n    # if epoch % 50 == 0:\n    #     total_time = time.perf_counter()-start_time\n    #     print(f\"Epoch {epoch}: train loss={loss_train[-1]}, val loss={loss_val[-1]}, time per epoch={total_time/50:0.4f} seconds\")\n    #     start_time = time.perf_counter()","visibility":"show","key":"ovo7bJzVIh"},{"type":"outputs","id":"Spmyb9gdw3-Vv0IutcHaI","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"  2%|▎                  | 78/5000 [00:07<08:15,  9.94it/s, train loss=0.09822165966033936, val loss=0.3268299996852875]"},"children":[],"key":"f2ZEm8bvbG"},{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"early stopping at epoch 78: train loss=0.09671168774366379, val loss=0.32835304737091064\n"},"children":[],"key":"BMbKWsYTMs"},{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"\n"},"children":[],"key":"dFqaznwv8V"}],"visibility":"show","key":"hB15LkJ9Un"}],"visibility":"show","key":"O3P2DM9LPM"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# restore best model\nPATH_CHECKPOINT = \"./checkpoint/best_masked.pt\"\nmodel.load_state_dict(torch.load(PATH_CHECKPOINT))\nprint(f\"best loss={best_loss}, model eval loss={validation(test_dataset, device)} at epoch {best_epoch}\")","visibility":"show","key":"gE8f8n2ABI"},{"type":"outputs","id":"4oA7y4-dVa4B1gxBWlsgd","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"best loss=0.3240234851837158, model eval loss=0.4523429274559021 at epoch 58\n"},"children":[],"key":"Q7uKRbw7Rv"}],"visibility":"show","key":"AqFMBhVq8X"}],"visibility":"show","key":"Xvlz3BovU9"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"data = test_dataset[0]\nmodel = model.to('cpu')\ndata.out = model(data.pos, data.signal, data.edge_index, data.edge_weight, torch.tensor(np.zeros([data.signal.shape[0]])).type(torch.BoolTensor)).detach()\ndata.out.shape","visibility":"show","key":"bf4TQU0Fxg"},{"type":"outputs","id":"79mpU2bHlFBa8Pbna1Tj6","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":21,"metadata":{},"data":{"text/plain":{"content":"torch.Size([9, 10])","content_type":"text/plain"}}},"children":[],"key":"pzlHcc6r56"}],"visibility":"show","key":"ocWNaJuOTs"}],"visibility":"show","key":"iWkFHiuo1J"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"data.error = np.abs(data.signal.detach()-data.out.detach()).sum(axis=1).reshape(data.signal.shape[0],1)\nvisualize_graph_torch(data, color=\"error\")","visibility":"show","key":"WRVuwsAWDD"},{"type":"outputs","id":"9cZ2cZkQJ_4_TmCXJBknm","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"78319714314c543e2ac9c7605a367dac","path":"/78319714314c543e2ac9c7605a367dac.png"},"text/plain":{"content":"<Figure size 600x600 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"pE1RsOXaik"}],"visibility":"show","key":"IrQN4nZGg5"}],"visibility":"show","key":"ZoUm8LPNMK"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"visualize_graph_torch(data, color=\"out\")","visibility":"show","key":"v28NIEhzbl"},{"type":"outputs","id":"PH8eGLuirUpoYtVi-xA4B","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"bc425464d5f14ea2551f47a0c8c42960","path":"/bc425464d5f14ea2551f47a0c8c42960.png"},"text/plain":{"content":"<Figure size 600x600 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"ddj5GdD3YB"}],"visibility":"show","key":"njbCUOKlwp"}],"visibility":"show","key":"EWT0pNCREa"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"for i in range(data.signal.shape[0]):\n    plt.plot(data.out[i], label=i)\n#plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))","visibility":"show","key":"z7hSPbNQag"},{"type":"outputs","id":"E4NE7kcd0uqyysXraieEC","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"7e4f1ed5b985479c05b57155dab08334","path":"/7e4f1ed5b985479c05b57155dab08334.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"JfMyreaFqz"}],"visibility":"show","key":"l3et0g7h77"}],"visibility":"show","key":"AcdhbrJABw"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"for i in range(data.signal.shape[0]):\n    plt.plot(data.signal[i]-data.out[i], label=i)\n    #plt.plot(data.signal[i])\n#plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.title(\"denoised data\")\nplt.ylim(-1.1, 1.1)","visibility":"show","key":"S49wPMxDwa"},{"type":"outputs","id":"8tJXhAcbihSHkQDWYLIPW","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":25,"metadata":{},"data":{"text/plain":{"content":"(-1.1, 1.1)","content_type":"text/plain"}}},"children":[],"key":"mIvA8o5XmX"},{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"b353fcb222cd1a595a1b696c8799884e","path":"/b353fcb222cd1a595a1b696c8799884e.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"DT8g89Nxfd"}],"visibility":"show","key":"OhvWdtTW6Q"}],"visibility":"show","key":"EhR6f0Q6qD"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"test_node = test_dataset[0].train_mask.nonzero()[0][0]\nplt.title(f\"results at node {test_node}\")\nplt.plot(data.out[test_node][:50], label=\"Prediction\")\nplt.plot(data.signal[test_node][:50], label=\"input\")\nplt.plot(data.signal[test_node][:50]-data.out[test_node][:50], label=\"denoised\")\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))","visibility":"show","key":"E0iQHGBNNB"},{"type":"outputs","id":"vaxKoUFpoHG43PtDlIzVT","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"86e4ea1bf066ef5a7c50aa709a4c7f70","path":"/86e4ea1bf066ef5a7c50aa709a4c7f70.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"MUQciVgVMV"}],"visibility":"show","key":"krZ9wTnT8p"}],"visibility":"show","key":"ITHG0ljJUf"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"plt.plot(loss_train, label=\"Train\")\nplt.plot(loss_val, label = \"Validation\")\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5))","visibility":"show","key":"XGEHidjIZ2"},{"type":"outputs","id":"BEUEDYOdKgHckbmfcbloh","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"c63486dc616d54035a0254e1d5d6b730","path":"/c63486dc616d54035a0254e1d5d6b730.png"},"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"}}},"children":[],"key":"flMcEYsZ5y"}],"visibility":"show","key":"u8ChPlXCBN"}],"visibility":"show","key":"teEt6DZ4DT"}],"key":"xsLnneYVMx"},"references":{"cite":{"order":[],"data":{}}}}