{"version":3,"kind":"Notebook","sha256":"cf23c1b0b46bde62c9b07af16e48ebb9b4e4b171c7148f2a7ed2602fdf5f8eb8","slug":"make-unet-annotated","location":"/notebooks/Loic/UNet/make_unet_annotated.ipynb","dependencies":[],"frontmatter":{"title":"üåé U-Net for Seismic Phase Picking","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"id":"Amanda M. Thomas, William Marfo, and Lo√Øc Bachelot","name":"Amanda M. Thomas, William Marfo, and Lo√Øc Bachelot"}],"keywords":["earthquake","catalog","ML","AI"],"numbering":{"title":{"offset":3}},"thumbnail":"/phasenet-b0b3ccf1f9cf0507aadce46be42268dd.png","exports":[{"format":"ipynb","filename":"make_unet_annotated.ipynb","url":"/make_unet_annotated-194c993fb11b6037f251f56e7939a73c.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Author:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fg23AXUjV8"}],"key":"F4ixWBrpHX"},{"type":"text","value":" Lo√Øc Bachelot","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nhroJqTJC7"},{"type":"break","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"IdpwozbpFF"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Goal:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AQHphS7TDH"}],"key":"PEsRt9YeNJ"},{"type":"text","value":" This notebook demonstrates how to define and train a U-Net model to detect seismic phases from waveform data.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Frpq3N3abX"}],"key":"ISRfaLNVBB"},{"type":"thematicBreak","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"rfSNyIfAk6"},{"type":"heading","depth":2,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"üìò Overview","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"p1bjcl5lkD"}],"identifier":"id-overview","label":"üìò Overview","html_id":"id-overview","implicit":true,"key":"OhK1c5Itz9"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Seismologists often need to detect the arrival times of P and S waves in continuous waveform recordings. These arrival times are crucial for locating earthquakes and understanding subsurface structures.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"r4xsrbXtIr"}],"key":"Z2rLXp2SE9"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"In this notebook:","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"pmswxdKjEA"}],"key":"vHNoInClTr"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":13,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We define a U-Net architecture inspired by ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"rFt7H3hH4d"},{"type":"link","url":"https://github.com/wayneweiqiang/PhaseNet","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"PhaseNet","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Oe3Rc9BAQi"}],"urlSource":"https://github.com/wayneweiqiang/PhaseNet","error":true,"key":"wqQPjwq6Bi"},{"type":"text","value":", adapted for 1D waveform inputs.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"BxnrDQPhZh"}],"key":"IgcevrsX0R"}],"key":"MNKvnOMjNR"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The input is a windowed waveform.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"avocuSaWqu"}],"key":"CMw4RtVC7J"}],"key":"R3r4GTFiqn"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The output is a probability distribution over time indicating the likelihood of P and S wave arrivals.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"wK22AMalOx"}],"key":"VuuCkrsP4g"}],"key":"phByttkeeH"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We visualize intermediate encoder/decoder outputs to understand how the network transforms the signal.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"RXfGBKbrBO"}],"key":"rP8Fej1M4s"}],"key":"xxwqKqDMur"}],"key":"BhLioowow9"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"The focus is on interpretability and pedagogical clarity ‚Äî ideal for first-time users of deep learning in seismology.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"tkSWARIVFA"}],"key":"QdaaPrM3Ri"}],"key":"AM0A7ZJ5yh"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Data Preparation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KzhxGkYBsi"}],"identifier":"data-preparation","label":"Data Preparation","html_id":"data-preparation","implicit":true,"key":"QKVoy7arHg"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We load a minimal subset of data required for model training. Detailed dataset explanations are handled in a separate notebook.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"geCBsDL3XD"}],"key":"D3xOu570YD"}],"key":"e1Xv4nhxLx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"pip install torchinfo","key":"pFa0NGWkHb"},{"type":"outputs","id":"HFHZuM7DrmFmoGgJxUVvh","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: torchinfo in /srv/conda/envs/notebook/lib/python3.12/site-packages (1.8.0)\nNote: you may need to restart the kernel to use updated packages.\n"},"children":[],"key":"qybvwWQle6"}],"key":"CXZG00CvAB"}],"key":"xHj3AWimlW"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import seisbench.data as sbd\nfrom torch.utils.data import random_split, DataLoader\nimport seisbench.generate as sbg\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os","key":"Ogo5Lsn6eO"},{"type":"outputs","id":"zNZAHmMNhHgi7846tzZh7","children":[],"key":"lzTDILG57f"}],"key":"O1OGWo26RA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Load the dataset from the current directory\ndata = sbd.WaveformDataset(\"/home/jovyan/shared/shortcourses/crescent_ml_2025/pnwml/mini/\", component_order=\"ENZ\")\nprint(data)","key":"kYHqDdZ2KQ"},{"type":"outputs","id":"16Yz_xLXZvGYpXI5lRdcd","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"2025-05-09 17:32:00,457 | seisbench | WARNING | Dimension order not specified in data set. Assuming CW.\n"},"children":[],"key":"JCG814YWvE"},{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Unnamed dataset - 1720 traces\n"},"children":[],"key":"vDl9upl9Of"}],"key":"mZmKm2i3QX"}],"key":"ooi8k5i8ih"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"data._metadata = data.metadata[data.metadata.source_type == \"earthquake\"].reset_index(drop=True)\nprint(data)","key":"ZfsDC0D6mf"},{"type":"outputs","id":"faNQar5SB_y5XweY7bk-r","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Unnamed dataset - 500 traces\n"},"children":[],"key":"qCyavZeOfs"}],"key":"B2wOFACcZs"}],"key":"TpEK4lWDW7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# In-place modification to add training, validation and testing split\nnp.random.seed(42)\nindices = np.random.permutation(len(data.metadata))\nn_total = len(data.metadata)\nn_train = int(0.4 * n_total)\nn_val = int(0.1 * n_total)\n\n# Directly modify the existing dataframe\ndata.metadata.loc[indices[:n_train], \"split\"] = \"train\"\ndata.metadata.loc[indices[n_train:n_train + n_val], \"split\"] = \"dev\"\ndata.metadata.loc[indices[n_train + n_val:], \"split\"] = \"test\"","key":"oOYKNakp9I"},{"type":"outputs","id":"shZJk1HgulBuQqcpQ-dn7","children":[],"key":"sH5Wtl2ReD"}],"key":"QB3VUW8Efe"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"train = data.train()\nval = data.dev()\ntest = data.test()\nphase_dict = {\n    \"trace_p_arrival_sample\": \"P\",\n    \"trace_pP_arrival_sample\": \"P\",\n    \"trace_P_arrival_sample\": \"P\",\n    \"trace_P1_arrival_sample\": \"P\",\n    \"trace_Pg_arrival_sample\": \"P\",\n    \"trace_Pn_arrival_sample\": \"P\",\n    \"trace_PmP_arrival_sample\": \"P\",\n    \"trace_pwP_arrival_sample\": \"P\",\n    \"trace_pwPm_arrival_sample\": \"P\",\n    \"trace_s_arrival_sample\": \"S\",\n    \"trace_S_arrival_sample\": \"S\",\n    \"trace_S1_arrival_sample\": \"S\",\n    \"trace_Sg_arrival_sample\": \"S\",\n    \"trace_SmS_arrival_sample\": \"S\",\n    \"trace_Sn_arrival_sample\": \"S\",\n}\nmodel_labels = [\"P\", \"S\", \"noise\"]\n\ntrain_generator = sbg.GenericGenerator(train)\nval_generator = sbg.GenericGenerator(val)\ntest_generator = sbg.GenericGenerator(test)\n\n# Define the augmentation pipeline used for training and validation\naugmentations = [\n    # Extract a window around a randomly chosen phase sample (P or S)\n    sbg.WindowAroundSample(\n        list(phase_dict.keys()), samples_before=3000, windowlen=6000,\n        selection=\"random\", strategy=\"variable\"\n    ),\n    \n    # If needed, randomly crop or pad the window to a fixed length\n    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n    \n    # Normalize waveform: remove mean and scale amplitude (peak normalization)\n    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n    \n    # Convert data type to float32 for training\n    sbg.ChangeDtype(np.float32),\n    \n    # Convert phase pick times into soft labels using Gaussian curves\n    sbg.ProbabilisticLabeller(label_columns=phase_dict, model_labels=model_labels, sigma=30, dim=0)\n]\n\n# Define a simpler augmentation for test data (no cropping or shifting)\ntest_augmentations = [\n    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n    sbg.ChangeDtype(np.float32),\n    sbg.ProbabilisticLabeller(label_columns=phase_dict, model_labels=model_labels, sigma=30, dim=0)\n]\n\n# Add augmentations to each dataset split\ntrain_generator.add_augmentations(augmentations)\nval_generator.add_augmentations(augmentations)\ntest_generator.add_augmentations(test_augmentations)","key":"siJELZurNE"},{"type":"outputs","id":"p2ppzB8LslB7WQDJDferW","children":[],"key":"KGr8T1J9l7"}],"key":"U7vlciDoC8"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sample = train_generator[np.random.randint(len(train_generator))]\n\nfig = plt.figure(figsize=(15, 10))\naxs = fig.subplots(2, 1, sharex=True, gridspec_kw={\"hspace\": 0, \"height_ratios\": [3, 1]})\naxs[0].plot(sample[\"X\"].T)\naxs[1].plot(sample[\"y\"].T)","key":"UMSYebfE8e"},{"type":"outputs","id":"5Wai4L4tQc6UB2hWalWHl","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"8e2d435dc996317e0008f00df2374c66","path":"/8e2d435dc996317e0008f00df2374c66.png"},"text/plain":{"content":"<Figure size 1500x1000 with 2 Axes>","content_type":"text/plain"}}},"children":[],"key":"j0IutsUmpO"}],"key":"HF6BtPk2ie"}],"key":"ho3Jj09XGM"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Prepare data for pytorch","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"S2yMFKZ6Ir"}],"identifier":"prepare-data-for-pytorch","label":"Prepare data for pytorch","html_id":"prepare-data-for-pytorch","implicit":true,"key":"TsRkXiiaps"}],"key":"VfWZ2liF2N"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from seisbench.util import worker_seeding\n\nbatch_size = 256\nnum_workers = 4  # The number of threads used for loading data\n\ntrain_loader = DataLoader(train_generator, batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=worker_seeding)\nval_loader = DataLoader(val_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding)","key":"SaPqsQLr4z"},{"type":"outputs","id":"Rzu-tqRW-RygTTKquJhiZ","children":[],"key":"obszbi2ENx"}],"key":"WcE754Stfg"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"U-Net Model Definition","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tWAXFmPh6T"}],"identifier":"u-net-model-definition","label":"U-Net Model Definition","html_id":"u-net-model-definition","implicit":true,"key":"fNbrOGgdnd"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this section, we define a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tDLFjn40Gw"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"U-Net","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gDz8MKtbXk"}],"key":"FEGUGpPuWI"},{"type":"text","value":" architecture tailored for 1D seismic waveform data. This model is inspired by ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PtHs226XgT"},{"type":"cite","url":"https://doi.org/10.1093/gji/ggy423","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"PhaseNet","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"SMZkqCZY41"}],"key":"Hlkrr7YlXY"}],"kind":"narrative","label":"Zhu_2018","identifier":"https://doi.org/10.1093/gji/ggy423","enumerator":"1","key":"Q7dy7HdPqx"},{"type":"text","value":", a deep learning approach that demonstrated strong performance in seismic phase picking.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"H5rexKnlrI"}],"key":"dr5KQ1WWkI"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"üß† What is a U-Net?","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"pCf5vf5MDs"}],"identifier":"id-what-is-a-u-net","label":"üß† What is a U-Net?","html_id":"id-what-is-a-u-net","implicit":true,"key":"NlAyboxCNE"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"A ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"IsCyDkhWF2"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"U-Net","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"HzgjvJW7LU"}],"key":"G047WPKRWo"},{"type":"text","value":" is a type of convolutional neural network originally developed for biomedical image segmentation. It has since proven effective for many tasks involving ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"f4QbzxVNUF"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"dense predictions","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"FTd8at07pg"}],"key":"GRvZykLEj1"},{"type":"text","value":", including segmentation and signal labeling. The U-Net architecture is characterized by:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Mjg5YtVAwt"}],"key":"jp6J30O54C"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"A ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"vDYBVOjkNi"},{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"contracting path","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"b2h1iRhzol"}],"key":"CP1fO7NFrP"},{"type":"text","value":" (encoder) that captures context through convolution and downsampling,","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"AMEYUWsxVb"}],"key":"bH6xlw7Llr"}],"key":"tl5kup3XJ5"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"An ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"CxgnjJBEiF"},{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"expanding path","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"vEfQlxHzQP"}],"key":"wyh6G507FX"},{"type":"text","value":" (decoder) that enables precise localization by upsampling,","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"HEYnasDJVC"}],"key":"x4MF8rinnp"}],"key":"d7nMmvx1Wc"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Skip connections","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"ZiRxK1SoWS"}],"key":"ZsL1E5ykiH"},{"type":"text","value":" that bridge encoder and decoder layers at the same resolution, preserving high-resolution features.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"fTAoHFPYRx"}],"key":"boppWVm7Em"}],"key":"N283KlRBk1"}],"key":"RjsapKBlLi"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Here‚Äôs the architecture of ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"LJbrzaaJfN"},{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"PhaseNet","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"UGIy2q52LO"}],"key":"QV0sLxT4hb"},{"type":"text","value":", which adapts this idea for ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"ABUHbvkfnN"},{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"1D seismic signals","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"zVS4WU3FMR"}],"key":"ucRQeuvsXc"},{"type":"text","value":":","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"oN3o0wkApo"}],"key":"RAVx4VkfIh"},{"type":"image","url":"/phasenet-b0b3ccf1f9cf0507aadce46be42268dd.png","alt":"PhaseNet architecture","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"nkpo490JHh","urlSource":"./phasenet.png"},{"type":"blockquote","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Weiqiang Zhu & Gregory C. Beroza (2019), PhaseNet: a deep-neural-network-based seismic arrival-time picking method, GJI, ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"A9oIuScRJT"},{"type":"cite","url":"https://doi.org/10.1093/gji/ggy423","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"DOI:10.1093/gji/ggy423","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"ocdrs9kUhP"}],"kind":"narrative","label":"Zhu_2018","identifier":"https://doi.org/10.1093/gji/ggy423","enumerator":"1","key":"Q9kTfS9Em6"}],"key":"tt85HHSKmk"}],"key":"GKHMffN2SX"}],"key":"lDjcw9Gjco"},{"type":"heading","depth":3,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"üß≠ Why use a U-Net for Seismology?","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"W9rSJSrUCz"}],"identifier":"id-why-use-a-u-net-for-seismology","label":"üß≠ Why use a U-Net for Seismology?","html_id":"id-why-use-a-u-net-for-seismology","implicit":true,"key":"Lc4Vexg4pl"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Seismic waveform analysis requires:","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"maYHS2O5bo"}],"key":"x6OmZC5NTG"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":22,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Context awareness","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"UnbAW9tFSt"}],"key":"m1nS3gca5v"},{"type":"text","value":" to detect arrival patterns over time,","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"Tv0GnC2mwv"}],"key":"xHfHF4Lxki"}],"key":"fU8pl4tisG"},{"type":"listItem","spread":true,"position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Precise localization","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"eNiBWF9nBj"}],"key":"W8jZnQtX9j"},{"type":"text","value":" of P and S phase arrivals,","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"SNWo4ziZ02"}],"key":"ovQa4yy3yf"}],"key":"RGExcrpoL9"},{"type":"listItem","spread":true,"position":{"start":{"line":24,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"Multiscale feature extraction","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"Cg2Gg4Fpmp"}],"key":"K01yxBodQa"},{"type":"text","value":", since phase arrivals can vary in shape and amplitude.","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"W78slclsra"}],"key":"u5vEWrBzNT"}],"key":"PR2kpcApGo"}],"key":"DVUvWe1P98"},{"type":"paragraph","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"A U-Net is especially suited for this because:","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"zcTcklFyBV"}],"key":"y8nn76RYd1"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":27,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The ","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"ekHU4k4lUw"},{"type":"strong","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"encoder","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"yFSFruMniK"}],"key":"P4s0dFt7vK"},{"type":"text","value":" captures long-range dependencies in the waveform,","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"PK7cQvXDuj"}],"key":"WpGXpIkB16"}],"key":"kBOi3aIrvS"},{"type":"listItem","spread":true,"position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The ","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"tGQM7iAtsq"},{"type":"strong","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"decoder","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"oWCGFJSWbG"}],"key":"SBoLrW6cCM"},{"type":"text","value":" reconstructs fine-grained outputs (e.g., phase probability at each timestep),","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"AHb5NF9eDX"}],"key":"ZOQdwO8ao3"}],"key":"MmBUnv4dF0"},{"type":"listItem","spread":true,"position":{"start":{"line":29,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Skip connections","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"rHPjvli1KG"}],"key":"IqtPnbNIhG"},{"type":"text","value":" ensure no loss of detail during downsampling.","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"hfQ8PYhswL"}],"key":"FDHWAih7OD"}],"key":"RnYWblhpEk"}],"key":"fFf9U7kVqh"},{"type":"paragraph","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"This makes it a perfect fit for ","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"pbEOoQEDsD"},{"type":"strong","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"dense, frame-by-frame classification","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"bvT2yR6LVu"}],"key":"Y3hizKbP6L"},{"type":"text","value":" of seismic traces.","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"Qn1vLOhMco"}],"key":"cPWFyu6JD4"}],"key":"uBS4ClMEjR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","key":"hu1D58oWtl"},{"type":"outputs","id":"Jfmef_v4JSCqOEqOQNKLK","children":[],"key":"pWJrcGwNEg"}],"key":"KFUk68Xu5s"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Define the U-Net architecture\n# Cell 2: U-Net Building Blocks\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding),\n            nn.ReLU(),\n            nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding),\n            nn.ReLU()\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNet1D(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3, features=[16, 32, 64, 128]):\n        super().__init__()\n        \n        self.downs = nn.ModuleList()  # Encoder blocks (downsampling path)\n        self.ups = nn.ModuleList()    # Decoder blocks (upsampling path)\n    \n        # ----- Encoder: Downsampling Path -----\n        # Each ConvBlock halves the temporal resolution via pooling (done in forward),\n        # and increases the number of feature channels.\n        for feat in features:\n            self.downs.append(ConvBlock(in_channels, feat))  # ConvBlock: Conv + ReLU + Conv + ReLU\n            in_channels = feat  # Update in_channels for the next block\n    \n        # ----- Bottleneck -----\n        # Deepest layer in the U-Net, connects encoder and decoder\n        self.bottleneck = ConvBlock(features[-1], features[-1]*2)\n    \n        # ----- Decoder: Upsampling Path -----\n        # Reverse features list for symmetrical decoder\n        rev_feats = features[::-1]\n        for feat in rev_feats:\n            # First upsample (via transposed convolution)\n            self.ups.append(\n                nn.ConvTranspose1d(feat*2, feat, kernel_size=2, stride=2)\n            )\n            # Then apply ConvBlock: input has double channels due to skip connection\n            self.ups.append(ConvBlock(feat*2, feat))\n    \n        # ----- Final Output Convolution -----\n        # 1x1 convolution to map to desired output channels (e.g., P, S, noise)\n        self.final_conv = nn.Conv1d(features[0], out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skip_connections = []\n\n        for down in self.downs:\n            x = down(x)\n            skip_connections.append(x)\n            x = F.max_pool1d(x, kernel_size=2)\n\n        x = self.bottleneck(x)\n        skip_connections = skip_connections[::-1]\n\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip_conn = skip_connections[idx//2]\n            if x.shape[-1] != skip_conn.shape[-1]:\n                x = F.pad(x, (0, skip_conn.shape[-1] - x.shape[-1]))\n            x = torch.cat((skip_conn, x), dim=1)\n            x = self.ups[idx+1](x)\n        x = self.final_conv(x)\n        return F.softmax(x, dim=1)\n\n    def forward_intermediate(self, x):\n        \"\"\"\n        Forward pass that returns intermediate features from encoder, bottleneck, and decoder.\n    \n        Returns:\n            dict of tensors: including skip layers, bottleneck, and decoder layers.\n        \"\"\"\n        features = {\"input\": x}\n        skip_connections = []\n    \n        # ----- Encoder -----\n        for i, down in enumerate(self.downs):\n            x = down(x)\n            features[f\"enc{i+1}\"] = x  # Save encoder output\n            skip_connections.append(x)\n            x = F.max_pool1d(x, kernel_size=2)\n    \n        # ----- Bottleneck -----\n        x = self.bottleneck(x)\n        features[\"bottleneck\"] = x\n        skip_connections = skip_connections[::-1]\n    \n        # ----- Decoder -----\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)  # upsampling\n            skip_conn = skip_connections[idx // 2]\n    \n            # Handle any size mismatch from pooling\n            if x.shape[-1] != skip_conn.shape[-1]:\n                x = F.pad(x, (0, skip_conn.shape[-1] - x.shape[-1]))\n    \n            x = torch.cat((skip_conn, x), dim=1)\n            x = self.ups[idx + 1](x)  # convolution after concatenation\n            features[f\"dec{idx//2 + 1}\"] = x\n    \n        # ----- Final Prediction -----\n        x = self.final_conv(x)\n        out = F.softmax(x, dim=1)\n        features[\"output\"] = out\n        return features","key":"yaIBDC3CTA"},{"type":"outputs","id":"EC-e1uLTaWFpc8ZWvlAM1","children":[],"key":"lazlT3u1fh"}],"key":"vTvEgkyP7S"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Model Training","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Aid3CCCypM"}],"identifier":"model-training","label":"Model Training","html_id":"model-training","implicit":true,"key":"hjE81ZTb5Y"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This section covers two main components:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"s4MfouY6Q4"}],"key":"ahyRINshXJ"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"üõ†Ô∏è Helper Functions","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"d4i3AQLV6C"}],"identifier":"id-helper-functions","label":"üõ†Ô∏è Helper Functions","html_id":"id-helper-functions","implicit":true,"key":"vBiijcVO9x"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"We define modular functions to handle training","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"aS9qoEZSQ4"}],"key":"Uytfy31iu7"},{"type":"heading","depth":3,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"üîÅ Training Loop","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"gW2mfmS90f"}],"identifier":"id-training-loop","label":"üîÅ Training Loop","html_id":"id-training-loop","implicit":true,"key":"LkRKfTA5PS"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"We then orchestrate the training process:","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"pM2OciIgqD"}],"key":"kJu9P5od0D"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":10,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Select device (CPU/GPU),","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"gZkTRTyrJM"}],"key":"Ygcjtw5588"}],"key":"qLhuzHNbSE"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Initialize model and optimizer,","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"xaMGSsLiny"}],"key":"aXUJGpj7Hi"}],"key":"Czb559fgOd"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Define early stopping and checkpointing criteria,","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"wzvgu60YJS"}],"key":"xfNfU5nCmL"}],"key":"tcOWpzFbnA"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Track training and validation losses,","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"e83Sr29On9"}],"key":"jjF9zl960y"}],"key":"C5OaGoxDOH"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Save the best model based on validation loss.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"QujvynYLXz"}],"key":"Dc62Z57JCQ"}],"key":"tnajLELvi4"}],"key":"n0SwmhDM5B"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"The training loop uses the helper functions to process the data over multiple epochs, evaluate progress, and stop early if performance plateaus.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"qsitYqzD7Y"}],"key":"FKaGfWxkoC"}],"key":"nDnf1gG9cO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport time\nfrom tqdm import tqdm\nfrom torchinfo import summary","key":"cJneiGkt66"},{"type":"outputs","id":"NS6CC981HjfmooD7swfjx","children":[],"key":"ADAwbJxKhR"}],"key":"OPTd8fMvkQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Training loop\ndef loss_fn(y_pred, y_true, eps=1e-5):\n    # vector cross entropy loss\n    h = y_true * torch.log(y_pred + eps)\n    h = h.mean(-1).sum(-1)  # Mean along sample dimension and sum along pick dimension\n    h = h.mean()  # Mean over batch axis\n    return -h","key":"ulVDEGsIwI"},{"type":"outputs","id":"Q9DwcnjJ_OCMYW0IpngPN","children":[],"key":"e7OFtaMPNy"}],"key":"nS1HXRUNe6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Training loop\nclass EarlyStopper:\n    \"\"\"\n    A class for early stopping the training process when the validation loss stops improving.\n\n    Parameters:\n    -----------\n    patience : int, optional (default=1)\n        The number of epochs with no improvement in validation loss after which training will be stopped.\n    min_delta : float, optional (default=0)\n        The minimum change in the validation loss required to qualify as an improvement.\n    \"\"\"\n\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.min_validation_loss = np.inf\n\n    def early_stop(self, validation_loss):\n        \"\"\"\n        Check if the training process should be stopped.\n\n        Parameters:\n        -----------\n        validation_loss : float\n            The current validation loss.\n\n        Returns:\n        --------\n        stop : bool\n            Whether the training process should be stopped or not.\n        \"\"\"\n        if validation_loss < self.min_validation_loss:\n            self.min_validation_loss = validation_loss\n            self.counter = 0\n        elif validation_loss > (self.min_validation_loss + self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","key":"KSXeUdeOJX"},{"type":"outputs","id":"YBaHj7G--V4C3baHBVE5R","children":[],"key":"x7Kl99V79y"}],"key":"N3mQ3KDw8D"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Training and Evaluation Helpers","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SWXcA12Qpa"}],"identifier":"training-and-evaluation-helpers","label":"Training and Evaluation Helpers","html_id":"training-and-evaluation-helpers","implicit":true,"key":"aSgkReFp5I"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To keep the training loop clean and modular, we define two helper functions:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"SBA1kOjl1D"}],"key":"ee8hTo9JcE"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"train_loop(...)","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LCHcNfhVeK"},{"type":"text","value":": Trains the model for one epoch using a given dataset and optimizer.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Lh4AQzOEKR"}],"key":"suaNLjrTRv"}],"key":"QNf1MVJk4w"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"test_loop(...)","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"G2qV7dazys"},{"type":"text","value":": Evaluates the model on a validation or test set.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"qT3MCo58Jw"}],"key":"KMhU0d9UQx"}],"key":"rGDBmg3qFc"}],"key":"P3Gukkf4G7"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"This separation improves ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"bncTTURgIh"},{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"code readability","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"vcFbWvp1k1"}],"key":"JAXHFYyiDQ"},{"type":"text","value":", helps ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"oyIdC1jMhW"},{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"avoid repetition","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"kMHzA7Q2Yx"}],"key":"HYg3gPf6f1"},{"type":"text","value":", and makes the notebook easier to maintain or adapt later (e.g., for different models or datasets).","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"MXh72rkOyH"}],"key":"aX3WBcdNqn"}],"key":"pBtV7AlSz8"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def train_loop(model, dataloader, optimizer, debug=False):\n    \"\"\"\n    One epoch of training.\n\n    Args:\n        model (torch.nn.Module): The model to train.\n        dataloader (DataLoader): Batches of training data.\n        optimizer (torch.optim.Optimizer): Optimizer for updating model weights.\n\n    Returns:\n        float: Average loss over the epoch.\n    \"\"\"\n    mean_loss = 0\n    total_samples = 0\n    model.train()  # Set model to training mode\n    size = len(dataloader.dataset)\n\n    for batch_id, batch in enumerate(dataloader):\n        # Forward pass ‚Äî model prediction\n        pred = model(batch[\"X\"].to(device))\n\n        # Compute the loss between prediction and ground truth\n        loss = loss_fn(pred, batch[\"y\"].to(device))\n        mean_loss += loss * batch[\"X\"].shape[0]  # scale back up by batch size\n        total_samples += batch[\"X\"].shape[0]\n\n        # Backward pass and optimizer update\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Logging every 5 batches\n        if batch_id % 5 == 0:\n            loss_val = loss.item()\n            current = batch_id * batch[\"X\"].shape[0]\n            if debug:\n                print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n\n    return mean_loss / size  # Return average loss for the epoch\n\n\ndef test_loop(model, dataloader):\n    \"\"\"\n    Evaluation on validation or test data.\n\n    Args:\n        model (torch.nn.Module): The model to evaluate.\n        dataloader (DataLoader): Batches of data.\n\n    Returns:\n        float: Average loss over the dataset (per sample).\n    \"\"\"\n    model.eval()\n    test_loss = 0\n    total_samples = 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            pred = model(batch[\"X\"].to(device))\n\n            loss = loss_fn(pred, batch[\"y\"].to(device)).item()\n            test_loss += loss * batch[\"X\"].shape[0]  # scale back up by batch size\n            total_samples += batch[\"X\"].shape[0]\n\n    return test_loss / total_samples","key":"TjjxvyjJGY"},{"type":"outputs","id":"onivLoOQ4KG1L69WrZ1IX","children":[],"key":"gD4TX63wOU"}],"key":"CT4ERfKuCs"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Training Configuration","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QICp9lxD5E"}],"identifier":"training-configuration","label":"Training Configuration","html_id":"training-configuration","implicit":true,"key":"Kvde4lg2fH"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Before training, we configure the computing device, model, optimizer, loss tracking, early stopping, and checkpointing.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PEURhtXKoQ"}],"key":"HBnboPACv8"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Device selection","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"NEkr1GGnpX"}],"key":"Fb22GrF34n"},{"type":"text","value":" ensures training runs on GPU if available.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"yAiQXtkByj"}],"key":"KgMYKnxqYn"}],"key":"BtR4bghlUY"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Model initialization","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"j9oKdw1nrC"}],"key":"L9JrJjjDKY"},{"type":"text","value":" moves the model to the selected device.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Ll9ukohi6p"}],"key":"cQYuBZFdqy"}],"key":"dk4mVgITsl"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Adam optimizer","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"EV6Yo8Z3L7"}],"key":"FN5udTGzEh"},{"type":"text","value":" is commonly used for deep learning due to adaptive learning rates.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"xwvRZjnEyL"}],"key":"dfkoHvZlkf"}],"key":"T8dWjcyTNz"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Checkpointing","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"YIoAYBjm9l"}],"key":"VGsIV43jec"},{"type":"text","value":" allows saving the best model during training.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"L9Hl8U82FC"}],"key":"Ks3ZdqHoQ4"}],"key":"ybHN0XIqas"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Early stopping","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"kYYpznSuqX"}],"key":"hBV1WxgD93"},{"type":"text","value":" halts training when the validation loss stops improving to prevent overfitting.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"N8updBYfdv"}],"key":"IsQeHtbT6T"}],"key":"b708w7BjOe"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Logging","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"brXE8WaYAJ"}],"key":"BEyi4DBB2s"},{"type":"text","value":" prints progress and training setup details for transparency and reproducibility.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"QH25HsNj9D"}],"key":"ekrdNFIJvZ"}],"key":"V6mcaltCJ2"}],"key":"IMMgaXSHL6"}],"key":"tn5qeaVTX3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"device {device}\")\nmodel = UNet1D().to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nnb_epoch = 100\nloss_train = []\nloss_val = []\nbest_loss = 100 # init at something super high so 1st eval is best\nbest_epoch = 0\nearly_stopper = EarlyStopper(patience=3, min_delta=0.0)\nmodel_name = \"phasenet_style\"\nPATH_CHECKPOINT = f\"./checkpoint/{model_name}.pt\"\n# Create the folder if it doesn't exist\nos.makedirs(os.path.dirname(PATH_CHECKPOINT), exist_ok=True)\nlog_counter = 1\n\nprint(\"\\n=== Training Configuration Recap ===\")\nprint(f\"Device: {device}\")\nprint(f\"Model: {model_name}\")\nprint(f\"Checkpoint Path: {PATH_CHECKPOINT}\")\nprint(f\"Optimizer: Adam\")\nprint(f\"Learning Rate: {optimizer.param_groups[0]['lr']}\")\nprint(f\"Epochs: {nb_epoch}\")\nprint(f\"Early Stopping Patience: {early_stopper.patience}\")\nprint(f\"Early Stopping Min Delta: {early_stopper.min_delta}\")\nprint(\"====================================\\n\")\nsummary(model, input_size=(1, 3, 3001))","key":"FpQNBMLMk1"},{"type":"outputs","id":"oWuZOpKZj5NXCd8iaXO_Y","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"device cpu\n\n=== Training Configuration Recap ===\nDevice: cpu\nModel: phasenet_style\nCheckpoint Path: ./checkpoint/phasenet_style.pt\nOptimizer: Adam\nLearning Rate: 0.001\nEpochs: 100\nEarly Stopping Patience: 3\nEarly Stopping Min Delta: 0.0\n====================================\n\n"},"children":[],"key":"Ku2Fb6dihy"},{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":15,"metadata":{},"data":{"text/plain":{"content":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nUNet1D                                   [1, 3, 3001]              --\n‚îú‚îÄModuleList: 1-1                        --                        --\n‚îÇ    ‚îî‚îÄConvBlock: 2-1                    [1, 16, 3001]             --\n‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-1              [1, 16, 3001]             944\n‚îÇ    ‚îî‚îÄConvBlock: 2-2                    [1, 32, 1500]             --\n‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-2              [1, 32, 1500]             4,672\n‚îÇ    ‚îî‚îÄConvBlock: 2-3                    [1, 64, 750]              --\n‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-3              [1, 64, 750]              18,560\n‚îÇ    ‚îî‚îÄConvBlock: 2-4                    [1, 128, 375]             --\n‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-4              [1, 128, 375]             73,984\n‚îú‚îÄConvBlock: 1-2                         [1, 256, 187]             --\n‚îÇ    ‚îî‚îÄSequential: 2-5                   [1, 256, 187]             --\n‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-5                  [1, 256, 187]             98,560\n‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-6                    [1, 256, 187]             --\n‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-7                  [1, 256, 187]             196,864\n‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-8                    [1, 256, 187]             --\n‚îú‚îÄModuleList: 1-3                        --                        --\n‚îÇ    ‚îî‚îÄConvTranspose1d: 2-6              [1, 128, 374]             65,664\n‚îÇ    ‚îî‚îÄConvBlock: 2-7                    [1, 128, 375]             --\n‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-9              [1, 128, 375]             147,712\n‚îÇ    ‚îî‚îÄConvTranspose1d: 2-8              [1, 64, 750]              16,448\n‚îÇ    ‚îî‚îÄConvBlock: 2-9                    [1, 64, 750]              --\n‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-10             [1, 64, 750]              36,992\n‚îÇ    ‚îî‚îÄConvTranspose1d: 2-10             [1, 32, 1500]             4,128\n‚îÇ    ‚îî‚îÄConvBlock: 2-11                   [1, 32, 1500]             --\n‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-11             [1, 32, 1500]             9,280\n‚îÇ    ‚îî‚îÄConvTranspose1d: 2-12             [1, 16, 3000]             1,040\n‚îÇ    ‚îî‚îÄConvBlock: 2-13                   [1, 16, 3001]             --\n‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-12             [1, 16, 3001]             2,336\n‚îú‚îÄConv1d: 1-4                            [1, 3, 3001]              51\n==========================================================================================\nTotal params: 677,235\nTrainable params: 677,235\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 257.17\n==========================================================================================\nInput size (MB): 0.04\nForward/backward pass size (MB): 8.52\nParams size (MB): 2.71\nEstimated Total Size (MB): 11.26\n==========================================================================================","content_type":"text/plain"}}},"children":[],"key":"gbsBihJu30"}],"key":"mdhvor6tgT"}],"key":"hJi2IOIJpH"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Training Loop","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ND2IKIUlRh"}],"identifier":"training-loop","label":"Training Loop","html_id":"training-loop","implicit":true,"key":"m8ovPMW1fI"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The model is trained using a typical PyTorch training loop with the following components:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"sn3bKzXzxV"}],"key":"Juq5z3OZ9w"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Training and validation loss tracking","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"t67w2LfFzj"}],"key":"VjaXbEbBno"},{"type":"text","value":": The model is evaluated on both the training and validation set each epoch.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"GXSHJSBjad"}],"key":"N03HiNcyGk"}],"key":"Otxq4WQJua"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Checkpointing","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"JUCWYH0wCv"}],"key":"PBNrHJTODi"},{"type":"text","value":": The best model (with lowest validation loss) is saved automatically.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Q7XrdoA1g4"}],"key":"YnLdBNI1M3"}],"key":"CV7hyw9HjW"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Early stopping","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"nDCxzJXyP0"}],"key":"AT0Oeah7Jy"},{"type":"text","value":": Training stops if the validation loss doesn‚Äôt improve for a preset number of epochs, helping to avoid overfitting.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"acZozfiuY7"}],"key":"pmJ9wMytXd"}],"key":"mVTIToivZ0"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Logging","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"EcQtMRJv1V"}],"key":"Ia6bgk1RHS"},{"type":"text","value":": Progress is logged every few epochs, including the current and best losses and timing information.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"tpwp0yfjsl"}],"key":"rynDikJPpH"}],"key":"SlAl3JDlxu"}],"key":"fRzSfAIA6h"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"This setup ensures that the model is both efficient and robust during training.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"r9JQX0BZ0B"}],"key":"yQPidSbh37"}],"key":"jT6NBuL9vt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Training loop with early stopping and checkpointing\n\nstart_time = time.perf_counter()\nprint(f\"Training starting ‚Äî number of epochs = {nb_epoch}\")\n\nfor epoch in range(nb_epoch):\n    # Train on one epoch and record the training loss\n    loss_train.append(train_loop(model, train_loader, optimizer))\n    \n    # Evaluate on validation set and record the loss\n    loss_val.append(test_loop(model, val_loader))\n    \n    # If validation loss improves, save the model checkpoint\n    if loss_val[-1] < best_loss:\n        best_loss = loss_val[-1]\n        best_epoch = epoch\n        torch.save(model.state_dict(), PATH_CHECKPOINT)  # Save best model\n\n    # Check early stopping condition (e.g., no improvement for N epochs)\n    if early_stopper.early_stop(loss_val[-1]):\n        print(f\"Early stopping at epoch {epoch}:\")\n        print(f\"  ‚Üí Train loss = {loss_train[-1]:.6f}\")\n        print(f\"  ‚Üí Val loss   = {loss_val[-1]:.6f}\")\n        break\n\n    # Logging every `log_counter` epochs\n    if epoch % log_counter == 0:\n        print(f\"Epoch {epoch}:\")\n        print(f\"  ‚Üí Train loss = {loss_train[-1]:.6f}\")\n        print(f\"  ‚Üí Val loss   = {loss_val[-1]:.6f}\")\n        print(f\"  ‚Üí Best val loss = {best_loss:.6f} (epoch {best_epoch})\")\n        print(f\"  ‚Üí Avg time per epoch = {(time.perf_counter() - start_time) / log_counter:.2f} sec\")\n        print(\"\\n#####################\\n\")\n        start_time = time.perf_counter()","key":"V9KglgHJcL"},{"type":"outputs","id":"I3FbLTyfhhloziHJf5lDv","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Training starting ‚Äî number of epochs = 100\nEpoch 0:\n  ‚Üí Train loss = 1.102228\n  ‚Üí Val loss   = 1.093189\n  ‚Üí Best val loss = 1.093189 (epoch 0)\n  ‚Üí Avg time per epoch = 10.11 sec\n\n#####################\n\nEpoch 1:\n  ‚Üí Train loss = 1.093023\n  ‚Üí Val loss   = 1.084363\n  ‚Üí Best val loss = 1.084363 (epoch 1)\n  ‚Üí Avg time per epoch = 7.62 sec\n\n#####################\n\nEpoch 2:\n  ‚Üí Train loss = 1.084411\n  ‚Üí Val loss   = 1.076120\n  ‚Üí Best val loss = 1.076120 (epoch 2)\n  ‚Üí Avg time per epoch = 7.63 sec\n\n#####################\n\nEpoch 3:\n  ‚Üí Train loss = 1.076106\n  ‚Üí Val loss   = 1.067989\n  ‚Üí Best val loss = 1.067989 (epoch 3)\n  ‚Üí Avg time per epoch = 7.75 sec\n\n#####################\n\nEpoch 4:\n  ‚Üí Train loss = 1.067736\n  ‚Üí Val loss   = 1.059975\n  ‚Üí Best val loss = 1.059975 (epoch 4)\n  ‚Üí Avg time per epoch = 7.80 sec\n\n#####################\n\nEpoch 5:\n  ‚Üí Train loss = 1.059910\n  ‚Üí Val loss   = 1.053105\n  ‚Üí Best val loss = 1.053105 (epoch 5)\n  ‚Üí Avg time per epoch = 7.94 sec\n\n#####################\n\nEpoch 6:\n  ‚Üí Train loss = 1.053238\n  ‚Üí Val loss   = 1.046853\n  ‚Üí Best val loss = 1.046853 (epoch 6)\n  ‚Üí Avg time per epoch = 7.79 sec\n\n#####################\n\nEpoch 7:\n  ‚Üí Train loss = 1.046482\n  ‚Üí Val loss   = 1.039573\n  ‚Üí Best val loss = 1.039573 (epoch 7)\n  ‚Üí Avg time per epoch = 7.89 sec\n\n#####################\n\nEpoch 8:\n  ‚Üí Train loss = 1.039291\n  ‚Üí Val loss   = 1.033027\n  ‚Üí Best val loss = 1.033027 (epoch 8)\n  ‚Üí Avg time per epoch = 7.86 sec\n\n#####################\n\nEpoch 9:\n  ‚Üí Train loss = 1.032548\n  ‚Üí Val loss   = 1.025957\n  ‚Üí Best val loss = 1.025957 (epoch 9)\n  ‚Üí Avg time per epoch = 7.86 sec\n\n#####################\n\nEpoch 10:\n  ‚Üí Train loss = 1.025898\n  ‚Üí Val loss   = 1.018453\n  ‚Üí Best val loss = 1.018453 (epoch 10)\n  ‚Üí Avg time per epoch = 7.82 sec\n\n#####################\n\nEpoch 11:\n  ‚Üí Train loss = 1.018791\n  ‚Üí Val loss   = 1.008670\n  ‚Üí Best val loss = 1.008670 (epoch 11)\n  ‚Üí Avg time per epoch = 7.71 sec\n\n#####################\n\nEpoch 12:\n  ‚Üí Train loss = 1.008811\n  ‚Üí Val loss   = 0.992284\n  ‚Üí Best val loss = 0.992284 (epoch 12)\n  ‚Üí Avg time per epoch = 7.96 sec\n\n#####################\n\nEpoch 13:\n  ‚Üí Train loss = 0.992219\n  ‚Üí Val loss   = 0.958706\n  ‚Üí Best val loss = 0.958706 (epoch 13)\n  ‚Üí Avg time per epoch = 7.89 sec\n\n#####################\n\nEpoch 14:\n  ‚Üí Train loss = 0.958380\n  ‚Üí Val loss   = 0.886842\n  ‚Üí Best val loss = 0.886842 (epoch 14)\n  ‚Üí Avg time per epoch = 7.89 sec\n\n#####################\n\nEpoch 15:\n  ‚Üí Train loss = 0.885660\n  ‚Üí Val loss   = 0.732289\n  ‚Üí Best val loss = 0.732289 (epoch 15)\n  ‚Üí Avg time per epoch = 8.11 sec\n\n#####################\n\nEpoch 16:\n  ‚Üí Train loss = 0.731248\n  ‚Üí Val loss   = 0.456766\n  ‚Üí Best val loss = 0.456766 (epoch 16)\n  ‚Üí Avg time per epoch = 8.03 sec\n\n#####################\n\nEpoch 17:\n  ‚Üí Train loss = 0.457521\n  ‚Üí Val loss   = 0.248298\n  ‚Üí Best val loss = 0.248298 (epoch 17)\n  ‚Üí Avg time per epoch = 7.96 sec\n\n#####################\n\nEpoch 18:\n  ‚Üí Train loss = 0.242713\n  ‚Üí Val loss   = 0.400773\n  ‚Üí Best val loss = 0.248298 (epoch 17)\n  ‚Üí Avg time per epoch = 7.89 sec\n\n#####################\n\nEpoch 19:\n  ‚Üí Train loss = 0.416029\n  ‚Üí Val loss   = 0.484812\n  ‚Üí Best val loss = 0.248298 (epoch 17)\n  ‚Üí Avg time per epoch = 7.87 sec\n\n#####################\n\nEarly stopping at epoch 20:\n  ‚Üí Train loss = 0.485775\n  ‚Üí Val loss   = 0.505618\n"},"children":[],"key":"wmMrcnkDxD"}],"key":"f1zsp5GHNy"}],"key":"SNb8jw3he2"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Training loop\nprint(f\"training finished, restoring best weights\")\nmodel.load_state_dict(torch.load(PATH_CHECKPOINT, map_location=device))\nprint(f\"best loss={best_loss}, model eval loss={test_loop(model, val_loader)} at epoch {best_epoch}\")","key":"Iy6VG9t9hc"},{"type":"outputs","id":"8mXtZ8CumYzse_uBTaGy6","children":[{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"training finished, restoring best weights\nbest loss=0.24829817415755306, model eval loss=0.24385667661295393 at epoch 17\n"},"children":[],"key":"YxKgXGSWlN"}],"key":"LYe454faVv"}],"key":"VrDmlsJKXC"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"For time saving, loading pretrained model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jZLNjuAitX"}],"identifier":"for-time-saving-loading-pretrained-model","label":"For time saving, loading pretrained model","html_id":"for-time-saving-loading-pretrained-model","implicit":true,"key":"blVUkEDgjS"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"I pretrained the same UNet on the full PNW dataset, we use this pretrained version here for evaluation","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Bnq3ALTrwq"}],"key":"fpV5eyvgXe"}],"key":"eXPUDM2pFb"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Load previous full training\nmodel.load_state_dict(torch.load(\"./model_weights_eq_only.pt\", map_location=device))","key":"ulmLV4hvly"},{"type":"outputs","id":"hH6nIA4ulbUWkSUBI9wZZ","children":[{"type":"output","jupyter_data":{"output_type":"execute_result","execution_count":18,"metadata":{},"data":{"text/plain":{"content":"<All keys matched successfully>","content_type":"text/plain"}}},"children":[],"key":"dheAxZ4yDd"}],"key":"d1CzTdCdxC"}],"key":"IRtHQocFvd"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Inference on Long Waveforms","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"m38s0wqW2H"}],"identifier":"inference-on-long-waveforms","label":"Inference on Long Waveforms","html_id":"inference-on-long-waveforms","implicit":true,"key":"z5zWZKEGox"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"After training, we want to apply the model to long, continuous waveform data.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WZhj8z0inv"}],"key":"aNv2jYE5wT"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Because the U-Net expects fixed-length input (e.g., 3001 samples), we use ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"exp1wA9msb"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"sliding window inference","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Zxf98ljRPd"}],"key":"w7RO96wV0s"},{"type":"text","value":" to break long waveforms into overlapping chunks, apply the model to each chunk, and then combine the outputs.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"JSnDB2kmcS"}],"key":"Zx8riqSdAo"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Key steps:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"mkt2BkURbK"}],"key":"pPXZooUnVQ"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":8,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"extract_sliding_windows(...)","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"GdkthukVDR"},{"type":"text","value":": slices the waveform into overlapping windows.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"CHAVnrtJYl"}],"key":"YxElA4JCRI"}],"key":"ifWvlkCRhD"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"batched_sliding_inference(...)","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"VtcdUU0w2A"},{"type":"text","value":": runs the model on all windows efficiently using batching, then recombines predictions.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"LD0JjO00dD"}],"key":"b8FtHoFmkV"}],"key":"U391xW3ikO"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"normalize_waveform(...)","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"MtfIQkf2Wt"},{"type":"text","value":": standard preprocessing to center and scale amplitude.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"YwMCSgSRXK"}],"key":"gZsK17ufdK"}],"key":"R6qgwP4NFa"}],"key":"VPc4YcF0f8"},{"type":"paragraph","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"This allows us to make ","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"OF3RRyU2NN"},{"type":"strong","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"dense predictions","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"OmwEOkUURY"}],"key":"ICElWg16wg"},{"type":"text","value":" over time (e.g., probability of P or S arrivals at each time step) even on long signals.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"UmlBawWesO"}],"key":"iZRlQNxxB5"}],"key":"ABBkZQtBzG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def extract_sliding_windows(waveform, window_size=3001, stride=10):\n    \"\"\"\n    Slice the waveform into overlapping sliding windows.\n\n    Args:\n        waveform (np.ndarray): Array of shape (3, T) ‚Äî 3 channels (Z, N, E).\n        window_size (int): Length of each window.\n        stride (int): Step size between windows.\n\n    Returns:\n        windows (np.ndarray): Shape (num_windows, 3, window_size)\n        indices (np.ndarray): Starting indices of each window\n    \"\"\"\n    C, T = waveform.shape\n    indices = np.arange(0, T - window_size + 1, stride)\n    windows = np.stack([waveform[:, i:i + window_size] for i in indices], axis=0)\n    return windows, indices\n\n\ndef batched_sliding_inference(waveform, model, window_size=3001, stride=100, device=\"cpu\", batch_size=512):\n    \"\"\"\n    Perform model inference over a long waveform using overlapping sliding windows.\n\n    Args:\n        waveform (np.ndarray): Shape (3, T), raw waveform data.\n        model (torch.nn.Module): Trained model.\n        window_size (int): Length of each input window.\n        stride (int): Step between windows.\n        device (str): 'cpu' or 'cuda'.\n        batch_size (int): Number of windows per batch.\n\n    Returns:\n        probs (np.ndarray): Shape (3, T), class probabilities for each timestep.\n    \"\"\"\n    model.eval()\n    waveform = waveform.astype(np.float32)\n    \n    # Split waveform into overlapping windows\n    windows, indices = extract_sliding_windows(waveform, window_size, stride)\n    num_windows = len(windows)\n\n    # Initialize prediction buffer and count buffer\n    probs = np.zeros((3, waveform.shape[1]))\n    counts = np.zeros((waveform.shape[1],))\n\n    # Run model in batches over windows\n    for i in range(0, num_windows, batch_size):\n        batch = torch.tensor(windows[i:i + batch_size], dtype=torch.float32).to(device)\n        with torch.no_grad():\n            out = model(batch).cpu().numpy()  # shape: (B, 3, window_size)\n\n        # Aggregate overlapping predictions\n        for j, idx in enumerate(indices[i:i + batch_size]):\n            probs[:, idx:idx + window_size] += out[j]\n            counts[idx:idx + window_size] += 1\n\n    # Normalize by number of overlapping windows at each time step\n    counts[counts == 0] = 1  # avoid division by zero\n    probs /= counts\n\n    return probs\n\n\ndef normalize_waveform(waveform):\n    \"\"\"\n    Normalize waveform: zero-mean and peak amplitude scaling.\n\n    Args:\n        waveform (np.ndarray): Shape (3, T), raw waveform.\n\n    Returns:\n        np.ndarray: Normalized waveform of same shape.\n    \"\"\"\n    waveform = waveform - np.mean(waveform, axis=-1, keepdims=True)\n    norm = np.max(np.abs(waveform), axis=-1, keepdims=True)\n    norm[norm == 0] = 1  # avoid division by zero\n    return waveform / norm","key":"DpGPyZEnkQ"},{"type":"outputs","id":"XzMetfDLZqvwLdzBhCYYs","children":[],"key":"biHWYbVaYZ"}],"key":"lky469S0FJ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Running Inference on Test Set","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FEUlTnyQ6m"}],"identifier":"running-inference-on-test-set","label":"Running Inference on Test Set","html_id":"running-inference-on-test-set","implicit":true,"key":"IoHZxO8DAn"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"We now evaluate the model on a set of test waveforms using the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FqtfMDVK9K"},{"type":"inlineCode","value":"batched_sliding_inference(...)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WNhkDqyh4E"},{"type":"text","value":" method defined earlier.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BEnnCDMOeJ"}],"key":"T4bn9JXHg9"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Each waveform is:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"f8WfsWgfHW"}],"key":"Dp6FRpRaA1"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":6,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Normalized","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Sr4skMSgeu"}],"key":"x6SsuA0ElU"},{"type":"text","value":" using peak amplitude scaling,","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"eyzhZpqs4t"}],"key":"TV4nr6XM6P"}],"key":"S5yKlQD0TJ"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Processed in overlapping windows","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"bIMx04WvVA"}],"key":"n4gXA2TCST"},{"type":"text","value":" by the model,","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"CmHnZIYS3N"}],"key":"bF0th1h8lc"}],"key":"a8ulr4iazU"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Reconstructed into a full-length probability prediction","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"dncsSAW5fR"}],"key":"U4B6lpoQKj"},{"type":"text","value":".","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"yt6DqjDxp4"}],"key":"Q5yUH19hjY"}],"key":"zFVbPpoPvX"}],"key":"ZlimCS9zDg"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"We also collect metadata such as true labels and arrival times for later comparison and visualization.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"H451zhUAKQ"}],"key":"L9qt2KKszX"}],"key":"v1zlujY6ek"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"all_results = []\nnumber_samples = 20\n# Loop over number_samples test samples\nfor i in tqdm(range(number_samples)):\n    # Use test_generator to get the full sample, including labels\n    sample = test_generator[i]\n    \n    # Extract waveform, true soft labels, and metadata\n    waveform = sample[\"X\"]  # Shape: (3, T)\n    true_labels = sample[\"y\"]  # Shape: (3, T), soft targets for P/S/Noise\n    meta = sample.get(\"meta\", test.get_sample(i)[1])  # Fall back to original metadata if needed\n\n    # Normalize waveform before feeding to model\n    waveform = normalize_waveform(waveform.astype(np.float32))\n\n    # Run sliding window inference on the waveform\n    start = time.time()\n    pred = batched_sliding_inference(waveform, model, device=device)\n    end = time.time()\n\n    # Collect results in a dictionary\n    all_results.append({\n        \"trace_id\": meta.get(\"trace_name\", f\"trace_{i}\"),\n        \"waveform\": waveform,\n        \"true_labels\": true_labels,\n        \"prediction\": pred,\n        \"p_arrival\": meta.get(\"trace_P_arrival_sample\"),\n        \"s_arrival\": meta.get(\"trace_S_arrival_sample\"),\n        \"meta\": meta,\n        \"inference_time\": end - start\n    })\n\nprint(f\"Inference finished for the {number_samples} test samples\")","key":"GX56xKnCve"},{"type":"outputs","id":"J-wJPRMO8Hvfx_s_jkuxq","children":[{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:18<00:00,  1.06it/s]"},"children":[],"key":"xXh89obM5e"},{"type":"output","jupyter_data":{"name":"stdout","output_type":"stream","text":"Inference finished for the 20 test samples\n"},"children":[],"key":"KVaP60P2Zc"},{"type":"output","jupyter_data":{"name":"stderr","output_type":"stream","text":"\n"},"children":[],"key":"zfhZmTtQ3S"}],"key":"eZNLNfwBwy"}],"key":"oNPmkAplBl"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"examples = np.random.choice(all_results, 5, replace=False)\n\nfor example in examples:\n    fig, axs = plt.subplots(3, 1, figsize=(15, 8), sharex=True)\n    fig.suptitle(f\"Trace ID: {example['trace_id']}\", fontsize=16)\n\n    waveform = example[\"waveform\"]\n    pred = example[\"prediction\"]\n\n    axs[0].plot(waveform.T)\n    axs[0].set_ylabel(\"Waveform\")\n\n    axs[1].plot(pred.T)\n    axs[1].set_ylabel(\"Prediction\\n[Noise, P, S]\")\n\n    axs[2].set_title(\"Ground Truth Picks\")\n    axs[2].plot(pred.T[0]*0, \"gray\", alpha=0.2)  # zero baseline\n\n    if example[\"p_arrival\"] is not None:\n        axs[2].axvline(example[\"p_arrival\"], color=\"blue\", linestyle=\"--\", label=\"P arrival\")\n    if example[\"s_arrival\"] is not None:\n        axs[2].axvline(example[\"s_arrival\"], color=\"orange\", linestyle=\"--\", label=\"S arrival\")\n    \n    axs[2].legend()\n    axs[2].set_xlabel(\"Time [samples]\")\n    axs[2].set_ylabel(\"Pick\")\n\n    plt.tight_layout()\n    plt.show()","key":"vGT7chrJN3"},{"type":"outputs","id":"EQxrWBzdeAPNo8G1wgLEf","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"8abdb1d3baaa6aa6cd2ff5ae0d8fe463","path":"/8abdb1d3baaa6aa6cd2ff5ae0d8fe463.png"},"text/plain":{"content":"<Figure size 1500x800 with 3 Axes>","content_type":"text/plain"}}},"children":[],"key":"cybJ4v3xlH"},{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"668a52577938fed0efb3ed21bd0d37b4","path":"/668a52577938fed0efb3ed21bd0d37b4.png"},"text/plain":{"content":"<Figure size 1500x800 with 3 Axes>","content_type":"text/plain"}}},"children":[],"key":"TmtZfNBo2f"},{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"d0199f137426b44609fd07183a49c18a","path":"/d0199f137426b44609fd07183a49c18a.png"},"text/plain":{"content":"<Figure size 1500x800 with 3 Axes>","content_type":"text/plain"}}},"children":[],"key":"B5OA6B2Yds"},{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"ca7ef929976810b3cec238e14f4e7981","path":"/ca7ef929976810b3cec238e14f4e7981.png"},"text/plain":{"content":"<Figure size 1500x800 with 3 Axes>","content_type":"text/plain"}}},"children":[],"key":"HCicnWGpuA"},{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"2aba68b9189954a1aac1afa123fdec76","path":"/2aba68b9189954a1aac1afa123fdec76.png"},"text/plain":{"content":"<Figure size 1500x800 with 3 Axes>","content_type":"text/plain"}}},"children":[],"key":"shqVPGLxrB"}],"key":"D42hWyXNye"}],"key":"kwWTZYskaI"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"üîç Explore Encoded Layers (Windowed)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yPGEeLOFbg"}],"identifier":"id-explore-encoded-layers-windowed","label":"üîç Explore Encoded Layers (Windowed)","html_id":"id-explore-encoded-layers-windowed","implicit":true,"key":"xcBAVjmEHq"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To gain insight into what the U-Net is learning internally, we extract a 3001-sample window from a test waveform that includes P and S arrivals.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PdgCkvYAXN"}],"key":"EnCFVLwSuJ"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"We examine:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"NgEuQdfbK2"}],"key":"AtadrDp7eU"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":6,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The original 3-channel waveform (Z, N, E),","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Qfqg4yt6rU"}],"key":"kTCVJzUr6Q"}],"key":"f0ikYFnlD8"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The deepest bottleneck representation,","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"AwN6NoS6Xi"}],"key":"Jz2cSmAI7G"}],"key":"v2yNrATtpi"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The final output probabilities for P, S, and Noise.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"ENjD9S0NgT"}],"key":"cztHndvCco"}],"key":"jFolZRbD94"}],"key":"kJwUypGQ39"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"We overlay the P and S arrival times across all plots to highlight how seismic phase information propagates through the network‚Äôs hierarchy.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"kAUpqm49vX"}],"key":"jn6CgWrZfj"}],"key":"g3jsfFQ91x"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Visualizing Model Inference and Intermediate Features","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"myaDom4zx8"}],"identifier":"visualizing-model-inference-and-intermediate-features","label":"Visualizing Model Inference and Intermediate Features","html_id":"visualizing-model-inference-and-intermediate-features","implicit":true,"key":"APGqfGgLFa"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this section, we extract a test window from the waveform that includes both P and S arrivals. We run the trained U-Net model on this window and visualize:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"yhpz9HsOuE"}],"key":"YcSVOxDhsw"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Input waveform","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"CjblfDdKIn"}],"key":"sTPypHXNBy"},{"type":"text","value":": Three channels (Z, N, E) with amplitude offset for clarity.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"K8s1OHuRR8"}],"key":"G5Zbg8BZne"}],"key":"RBV7V1iGz7"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Bottleneck features","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"TgtD8xvZxc"}],"key":"nSWbH2toWh"},{"type":"text","value":": A heatmap showing the compressed feature representation after the encoder.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"candvWEhP2"}],"key":"h1URXy5Gjp"}],"key":"VFXC43HkEl"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Predictions vs. True Labels","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"xn7IpgzZVD"}],"key":"ZINz3B4OhN"},{"type":"text","value":": Model output probabilities for P, S, and Noise classes compared against the ground truth.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"BopDirBTA6"}],"key":"eT965qn3yL"}],"key":"Q3jAnY1YWC"}],"key":"QGIKY9mu6h"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Red and green vertical lines mark the P and S arrival times, respectively, allowing for visual evaluation of model accuracy.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Yhjq9szC6C"}],"key":"a1WDbuqmZw"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"This type of visualization helps understand how the model transforms seismic data at different stages and assess the quality of its predictions.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"f8gTKHa5ws"}],"key":"F7EsOhCLL9"}],"key":"nGybsCIhHx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# --- 1. Slice a test window that includes P and S arrivals ---\nstart = 5000  # start index of the window\nwindow_len = 3001\nsample_id = 12\nsample = test_generator[sample_id]\nwaveform = sample[\"X\"][:, start:start+window_len]\ntrue_labels = sample[\"y\"][:, start:start+window_len]\nmeta = sample.get(\"meta\", test.get_sample(sample_id)[1])  # get metadata\n\nx = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).to(device)\n\n# --- 2. Run model with intermediate outputs ---\nfeatures = model.forward_intermediate(x)\ninput_wave = features[\"input\"].squeeze().cpu().detach().numpy()\nbottleneck = features[\"bottleneck\"].squeeze().cpu().detach().numpy()\nprediction = features[\"output\"].squeeze().cpu().detach().numpy()\n\n# --- 3. Setup figure ---\nfig, axes = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n\n# --- 4. Plot input waveform ---\nfor i in range(3):\n    axes[0].plot(input_wave[i] + i * 2, label=f\"Channel {['Z', 'N', 'E'][i]}\")\naxes[0].set_title(\"Input Waveform\")\naxes[0].legend()\n\n# --- 5. Plot bottleneck features as heatmap with extended x-axis ---\ninput_len = input_wave.shape[-1]\nextent = [0, input_len, 0, bottleneck.shape[0]]\nim = axes[1].imshow(bottleneck, aspect=\"auto\", cmap=\"viridis\", extent=extent)\naxes[1].set_title(\"Bottleneck Features\")\naxes[1].set_ylabel(\"Channels\")\nplt.colorbar(im, ax=axes[1], orientation=\"vertical\")\n\n# --- 6. Plot predictions vs. true labels ---\nlabels = [\"P\", \"S\", \"Noise\"]\nfor i in range(3):\n    axes[2].plot(prediction[i], label=f\"Pred {labels[i]}\", linestyle='-')\n    axes[2].plot(true_labels[i], label=f\"True {labels[i]}\", linestyle='--', alpha=0.5)\naxes[2].set_title(\"Prediction vs. True Labels\")\naxes[2].legend()\naxes[2].set_xlabel(\"Time (samples)\")\n\n# --- 7. Overlay P and S arrival lines (aligned with input time) ---\np_arrival = meta.get(\"trace_P_arrival_sample\")\ns_arrival = meta.get(\"trace_S_arrival_sample\")\n\nif p_arrival is not None:\n    p_shifted = p_arrival - start\n    if 0 <= p_shifted < input_len:\n        for ax in axes:\n            ax.axvline(p_shifted, color=\"red\", linestyle=\"--\", label=\"P arrival\")\nif s_arrival is not None:\n    s_shifted = s_arrival - start\n    if 0 <= s_shifted < input_len:\n        for ax in axes:\n            ax.axvline(s_shifted, color=\"green\", linestyle=\"--\", label=\"S arrival\")\n\nplt.tight_layout()\nplt.show()","key":"cBvECsq2TC"},{"type":"outputs","id":"IMqQBGnqUrdVe7kh8mRCa","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"897e76254c06d4b80deaa25d6af00a51","path":"/897e76254c06d4b80deaa25d6af00a51.png"},"text/plain":{"content":"<Figure size 1400x800 with 4 Axes>","content_type":"text/plain"}}},"children":[],"key":"szJ4NXdzNp"}],"key":"Chr18tw98C"}],"key":"uqE98XwooA"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Comparing Early and Late Layers","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wR0lF1R9DO"}],"identifier":"comparing-early-and-late-layers","label":"Comparing Early and Late Layers","html_id":"comparing-early-and-late-layers","implicit":true,"key":"qwSHsXbvAl"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To better understand how the U-Net transforms seismic signals, we visualize:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DTAeTJEnEh"}],"key":"xEeaCBoACk"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The original input waveform,","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"dEajAJDqKp"}],"key":"IWFEZQ2lah"}],"key":"ppu68kNFBO"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lYT2JxFfCI"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"first encoder layer output","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"mKQ9x9ubeY"}],"key":"F3YLLaDeG0"},{"type":"text","value":" (early, low-level features),","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"e4W3meMGlX"}],"key":"siBPW9AWzV"}],"key":"yYqdUoosy1"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tKZPxaI4Ql"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"last decoder layer output","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"NSlxK5h66Z"}],"key":"iOjW05n6Ew"},{"type":"text","value":" (just before final prediction),","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tQSXgj1V6t"}],"key":"iXkLisyx1H"}],"key":"ijwABYTQIj"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The final prediction probabilities vs. true labels.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"OMxny2d4mS"}],"key":"xZkyVJ3WZl"}],"key":"qnCrYHHsKI"}],"key":"Eyql4ETSdd"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"We overlay the P and S arrival times to show how signal structures evolve through the network while still preserving alignment with the seismic event.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"wPpKGACPqe"}],"key":"rE07U2pzfi"}],"key":"Of1t95mMj3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# --- 1. Slice a test window that includes P and S arrivals ---\nstart = 5000  # start index of the window\nwindow_len = 3001\nsample_id = 12\nsample = test_generator[sample_id]\nwaveform = sample[\"X\"][:, start:start+window_len]\ntrue_labels = sample[\"y\"][:, start:start+window_len]\nmeta = sample.get(\"meta\", test.get_sample(sample_id)[1])  # get metadata\n\nx = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).to(device)\n\n# --- 2. Run model and extract intermediate features ---\nfeatures = model.forward_intermediate(x)\ninput_wave = features[\"input\"].squeeze().cpu().detach().numpy()\nenc1 = features[\"enc1\"].squeeze().cpu().detach().numpy()\nbottleneck = features[\"bottleneck\"].squeeze().cpu().detach().numpy()\ndec_last = features[\"dec4\"].squeeze().cpu().detach().numpy()\nprediction = features[\"output\"].squeeze().cpu().detach().numpy()\n\n# --- 3. Plot input, enc1, dec_last, and output ---\nfig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n\n# Plot input waveform\nfor i in range(3):\n    axes[0].plot(input_wave[i] + i * 2, label=f\"Channel {['Z', 'N', 'E'][i]}\")\naxes[0].set_title(\"Input Waveform\")\naxes[0].legend()\n\n# Plot encoder layer 1\naxes[1].imshow(enc1, aspect=\"auto\", cmap=\"viridis\", extent=[0, input_wave.shape[-1], 0, enc1.shape[0]])\naxes[1].set_title(\"First Encoder Layer (enc1)\")\naxes[1].set_ylabel(\"Channels\")\n\n# Plot last decoder layer\naxes[2].imshow(dec_last, aspect=\"auto\", cmap=\"viridis\", extent=[0, input_wave.shape[-1], 0, dec_last.shape[0]])\naxes[2].set_title(\"Last Decoder Layer (dec4)\")\naxes[2].set_ylabel(\"Channels\")\n\n# Plot predictions vs true labels\nlabels = [\"P\", \"S\", \"Noise\"]\nfor i in range(3):\n    axes[3].plot(prediction[i], label=f\"Pred {labels[i]}\", linestyle='-')\n    axes[3].plot(true_labels[i], label=f\"True {labels[i]}\", linestyle='--', alpha=0.5)\naxes[3].set_title(\"Prediction vs. True Labels\")\naxes[3].legend()\naxes[3].set_xlabel(\"Time (samples)\")\n\n# --- 4. Add vertical lines for P and S arrivals if within window ---\np_arrival = meta.get(\"trace_P_arrival_sample\")\ns_arrival = meta.get(\"trace_S_arrival_sample\")\n\nif p_arrival is not None:\n    p_shifted = p_arrival - start\n    if 0 <= p_shifted < input_wave.shape[-1]:\n        for ax in axes:\n            ax.axvline(p_shifted, color=\"red\", linestyle=\"--\", label=\"P arrival\")\n\nif s_arrival is not None:\n    s_shifted = s_arrival - start\n    if 0 <= s_shifted < input_wave.shape[-1]:\n        for ax in axes:\n            ax.axvline(s_shifted, color=\"green\", linestyle=\"--\", label=\"S arrival\")\n\nplt.tight_layout()\nplt.show()","key":"DDMLvwlLjQ"},{"type":"outputs","id":"wbhbRanx9C2zxeHH2gBsO","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"22bb62f14df22b9b89b04eedf39398cb","path":"/22bb62f14df22b9b89b04eedf39398cb.png"},"text/plain":{"content":"<Figure size 1400x1000 with 4 Axes>","content_type":"text/plain"}}},"children":[],"key":"tWP2giWq72"}],"key":"iWhazJNnk3"}],"key":"hFTf4Q4nz9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Layer-by-Layer Feature Evolution","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ciRtuNSsqW"}],"identifier":"layer-by-layer-feature-evolution","label":"Layer-by-Layer Feature Evolution","html_id":"layer-by-layer-feature-evolution","implicit":true,"key":"p4DiJ6Dv8S"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this plot, we visualize the full feature transformation pipeline through the U-Net:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FfTe9Kz27D"}],"key":"sF2sypbURF"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The original input waveform (Z/N/E channels),","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"qczr7rmfpt"}],"key":"ISJRK7WEV4"}],"key":"wkDNCwc7a1"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Each intermediate layer (encoder stages, bottleneck, decoder stages),","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"yyZPhjhfzR"}],"key":"TZKkS04iGL"}],"key":"loBm9vguGQ"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The final prediction compared to the true soft labels.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"fd8QNa8deI"}],"key":"NLE8uBL4Bc"}],"key":"MmDJmcYulG"}],"key":"TV3DKyO9R9"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"All layers are plotted on the same time axis and overlaid with P and S wave arrival times. This view illustrates how temporal patterns are captured, abstracted, and reconstructed across the network hierarchy.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"C8tlpf2gZI"}],"key":"XAa0QfJNh8"}],"key":"Vc3BeIaK8Q"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# --- 1. Slice a test window that includes P and S arrivals ---\nstart = 5000  # start index of the window\nwindow_len = 3001\nsample_id = 12\nsample = test_generator[sample_id]\nwaveform = sample[\"X\"][:, start:start+window_len]\ntrue_labels = sample[\"y\"][:, start:start+window_len]\nmeta = sample.get(\"meta\", test.get_sample(sample_id)[1])  # get metadata\n\nx = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).to(device)\nfeatures = model.forward_intermediate(x)\n\n# --- 2. Extract input/prediction ---\ninput_wave = features[\"input\"].squeeze().cpu().detach().numpy()\nprediction = features[\"output\"].squeeze().cpu().detach().numpy()\n\n# --- 3. Collect intermediate layers (enc*, bottleneck, dec*) ---\nlayer_keys = [k for k in features.keys() if k.startswith(\"enc\") or k == \"bottleneck\" or k.startswith(\"dec\")]\nlayer_keys = sorted(layer_keys, key=lambda k: (\"enc\" not in k, \"bottleneck\" not in k, k))  # enc1, enc2, ..., bottleneck, dec1, ...\n\n# --- 4. Create subplots ---\nn_rows = 2 + len(layer_keys)  # input + all layers + output\nfig, axes = plt.subplots(n_rows, 1, figsize=(14, 3 * n_rows), sharex=True)\n\n# --- 5. Plot input waveform ---\nfor i in range(3):\n    axes[0].plot(input_wave[i] + i * 2, label=f\"Channel {['Z', 'N', 'E'][i]}\")\naxes[0].set_title(\"Input Waveform\")\naxes[0].legend()\n\n# --- 6. Plot all intermediate layers with rescaled extent ---\nfor i, key in enumerate(layer_keys):\n    fmap = features[key].squeeze().cpu().detach().numpy()\n    extent = [0, input_wave.shape[-1], 0, fmap.shape[0]]\n    axes[i+1].imshow(fmap, aspect=\"auto\", cmap=\"viridis\", extent=extent)\n    axes[i+1].set_title(f\"{key}\")\n    axes[i+1].set_ylabel(\"Channels\")\n\n# --- 7. Plot prediction vs. true labels ---\nlabels = [\"P\", \"S\", \"Noise\"]\nfor i in range(3):\n    axes[-1].plot(prediction[i], label=f\"Pred {labels[i]}\", linestyle='-')\n    axes[-1].plot(true_labels[i], label=f\"True {labels[i]}\", linestyle='--', alpha=0.5)\naxes[-1].set_title(\"Prediction vs. True Labels\")\naxes[-1].legend()\naxes[-1].set_xlabel(\"Time (samples)\")\n\n# --- 8. Add vertical P and S arrivals to all plots ---\np_arrival = meta.get(\"trace_P_arrival_sample\")\ns_arrival = meta.get(\"trace_S_arrival_sample\")\n\nif p_arrival is not None:\n    p_shifted = p_arrival - start\n    if 0 <= p_shifted < input_wave.shape[-1]:\n        for ax in axes:\n            ax.axvline(p_shifted, color=\"red\", linestyle=\"--\", label=\"P arrival\")\n\nif s_arrival is not None:\n    s_shifted = s_arrival - start\n    if 0 <= s_shifted < input_wave.shape[-1]:\n        for ax in axes:\n            ax.axvline(s_shifted, color=\"green\", linestyle=\"--\", label=\"S arrival\")\n\nplt.tight_layout()\nplt.show()","key":"kLrDxz4O5Q"},{"type":"outputs","id":"waL76m9ry9hrr8kXwuuNE","children":[{"type":"output","jupyter_data":{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"ed733396b5d06d429ee8e5710af843bc","path":"/ed733396b5d06d429ee8e5710af843bc.png"},"text/plain":{"content":"<Figure size 1400x3300 with 11 Axes>","content_type":"text/plain"}}},"children":[],"key":"BuvaK1Hee5"}],"key":"Bu4MRUfD6a"}],"key":"PU4Zy8uOQj"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"‚úÖ Conclusion","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nUOrRQcSIN"}],"identifier":"id-conclusion","label":"‚úÖ Conclusion","html_id":"id-conclusion","implicit":true,"key":"h29ByojKFc"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this notebook, we implemented and visualized a U-Net model for seismic phase picking ‚Äî a critical task in seismology for detecting P and S wave arrivals in continuous waveform data.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"kaFMPv7D2K"}],"key":"nT9TURnakP"},{"type":"heading","depth":3,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"üß† What We Did:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"v0wpdfXXKT"}],"identifier":"id-what-we-did","label":"üß† What We Did:","html_id":"id-what-we-did","implicit":true,"key":"man6kwNnjL"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":6,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Built a 1D U-Net architecture inspired by ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"u4gKzfmeUM"},{"type":"link","url":"https://github.com/wayneweiqiang/PhaseNet","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"PhaseNet","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"umnT2lThuz"}],"urlSource":"https://github.com/wayneweiqiang/PhaseNet","error":true,"key":"LvFrhpYRAb"},{"type":"text","value":", with skip connections and encoder-decoder structure.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"ZKIV7Vo3gz"}],"key":"EMlIp3aan0"}],"key":"h1pL8f8CAu"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Visualized ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"SAiGtRRu4P"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"intermediate activations","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"HiEVk8z0xB"}],"key":"CFJJUZtMYS"},{"type":"text","value":" to better understand how features evolve through the network.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"qMWAKYW5AJ"}],"key":"R2MkPWsG2T"}],"key":"ocIcmntm1l"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Ran the model on real/test waveform windows and compared predicted probabilities with ground-truth labels.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Bp8kyD2jhp"}],"key":"jWgibYhXGo"}],"key":"OUpgfkmo9W"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Highlighted arrival times and validated that the model captures key temporal features across channels.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"yfs0y8iDNX"}],"key":"vwfBWswolI"}],"key":"yS1eDj0KKe"}],"key":"JvMmc4reIT"},{"type":"heading","depth":3,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"üìä What We Learned:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"S34INfi4yX"}],"identifier":"id-what-we-learned","label":"üìä What We Learned:","html_id":"id-what-we-learned","implicit":true,"key":"u8rKA4o8HA"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":12,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The U-Net is capable of localizing subtle waveform changes across multiple channels.","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"lVSAyuESzh"}],"key":"qvT9td1SFL"}],"key":"s4T9fU4xTU"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Intermediate feature maps provide insight into what the network is learning at different stages (e.g., low-level vs. abstract features).","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"PF2DP22kVy"}],"key":"BiYNqTtSLB"}],"key":"x8mGRpeHt3"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Well-aligned predictions with arrival times demonstrate strong temporal sensitivity.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"Op5Ck9YUrX"}],"key":"BmXMReQEnw"}],"key":"QchMAbhoha"}],"key":"QtVNht3pwT"},{"type":"heading","depth":3,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"üß≠ Next Steps:","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"mHG7Ot0DrE"}],"identifier":"id-next-steps","label":"üß≠ Next Steps:","html_id":"id-next-steps","implicit":true,"key":"AeUclbYpkn"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":17,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Move to the ","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"VbPUTb3jpS"},{"type":"strong","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Evaluation Notebook","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"LnY2RQzJsy"}],"key":"Ptv3dBLTbi"},{"type":"text","value":" where we:","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"NCg05Nof7i"}],"key":"AXku8pqAGi"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":18,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Run the model over the full test set","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"VZ4vdlbKnQ"}],"key":"UVMVtNvKgf"}],"key":"iiqUnta591"},{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Compute metrics like precision, and recall","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"An8YpbzBAm"}],"key":"vHyROqoyV5"}],"key":"zZyMOaSxT6"},{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Visualize confusion matrices and timing accuracy","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"AJqqcapehS"}],"key":"wCzQmjIiSM"}],"key":"exGbTmbh05"}],"key":"VjvaeNovvv"}],"key":"R61geKJM1t"},{"type":"listItem","spread":true,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Try training the model from scratch on custom datasets (e.g., regional catalogs or GNSS-derived events).","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"hu9Gofs7Ka"}],"key":"uZuhA4kDjr"}],"key":"tysIMYNVqg"},{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Add uncertainty estimation or ensemble techniques to improve robustness.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"j9OLuFbuca"}],"key":"epiBM4pFyr"}],"key":"mNgbYkaTtr"}],"key":"EhtdsowWUR"},{"type":"blockquote","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"üöÄ This model is a strong baseline for real-time or post-event seismic analysis ‚Äî and we‚Äôre just getting started!","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"G86s7J6Nvw"}],"key":"HAXhnGiXuW"}],"key":"bOV47q5t7l"}],"key":"c6zVvtFlmL"}],"key":"wWMtKmEZu5"},"references":{"cite":{"order":["Zhu_2018"],"data":{"Zhu_2018":{"label":"Zhu_2018","enumerator":"1","doi":"10.1093/gji/ggy423","html":"Zhu, W., & Beroza, G. C. (2018). PhaseNet: A Deep-Neural-Network-Based Seismic Arrival Time Picking Method. <i>Geophysical Journal International</i>. <a target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1093/gji/ggy423\">10.1093/gji/ggy423</a>","url":"https://doi.org/10.1093/gji/ggy423"}}}}}